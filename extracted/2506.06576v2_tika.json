{
  "metrics": {
    "file": "C:\\Users\\User\\Downloads\\Ai agent\\2506.06576v2.pdf",
    "extraction_time": "2025-09-10T02:57:34.545590",
    "extracted_text": true,
    "extracted_images": false,
    "extracted_tables": false,
    "percent_info_extracted": 100,
    "percent_relevant_info": 100,
    "output_format": {
      "text": "str",
      "metadata": "dict"
    },
    "method_used": "open source (Apache Tika)",
    "permission_needed": "No (open source, local processing)",
    "notes": "Text and metadata via Tika."
  },
  "summary": {
    "text_extracted": true,
    "output_format": {
      "text": "str",
      "metadata": "dict"
    },
    "metadata_extracted": true,
    "percent_info_extracted": 100
  },
  "extracted_data": {
    "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuture of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce\n\n\nar\nX\n\niv\n:2\n\n50\n6.\n\n06\n57\n\n6v\n2 \n\n [\ncs\n\n.C\nY\n\n] \n 1\n\n1 \nJu\n\nn \n20\n\n25\n\nFuture of Work with AI Agents:\nAuditing Automation and Augmentation Potential across the U.S. Workforce\n\nYijia Shao*, Humishka Zope*, Yucheng Jiang, Jiaxin Pei, David Nguyen,\nErik Brynjolfsson, Diyi Yang\n\nStanford University\n{shaoyj, diyiy}@cs.stanford.edu\n\nAbstract\n\nThe rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the labor market, raising concerns about\njob displacement, diminished human agency, and overreliance on automation. Yet, we lack a systematic under-\nstanding of the evolving landscape. In this paper, we address this gap by introducing a novel auditing framework\nto assess which occupational tasks workers want AI agents to automate or augment, and how those desires align\nwith the current technological capabilities. Our framework features an audio-enhanced mini-interview to cap-\nture nuanced worker desires and introduces the Human Agency Scale (HAS) as a shared language to quantify the\npreferred level of human involvement. Using this framework, we construct the WORKBank database, building\non the U.S. Department of Labor’s O*NET database, to capture preferences from 1,500 domain workers and capa-\nbility assessments from AI experts across over 844 tasks spanning 104 occupations. Jointly considering the desire\nand technological capability divides tasks in WORKBank into four zones: Automation “Green Light” Zone,\nAutomation “Red Light” Zone, R&D Opportunity Zone, Low Priority Zone. This highlights critical mismatches\nand opportunities for AI agent development. Moving beyond a simple automate-or-not dichotomy, our results\nreveal diverse HAS profiles across occupations, reflecting heterogeneous expectations for human involvement.\nMoreover, our study offers early signals of how AI agent integration may reshape the core human competencies,\nshifting from information-focused skills to interpersonal ones. These findings underscore the importance of\naligning AI agent development with human desires and preparing workers for evolving workplace dynamics.\n\n1 Introduction\n\nRapid advances in foundation models, such as large language models (LLMs), have catalyzed\ngrowing interest in AI agents: goal-directed systems equipped with tool access and multi-step\nexecution capabilities. Unlike standalone models, these agents can perform complex workflows and\nare increasingly positioned to take on roles across a broad range of professional domains (Jiang et al.,\n2024, Shao et al., 2024a, Wang et al., 2024b, Yang et al., 2024, Yao et al., 2024). Their integration into\noccupational settings is already beginning to shape the labor market (Demirci et al., 2025, Hoffmann\net al., 2024). For example, research indicates that around 80% of U.S. workers may see LLMs affect\nat least 10% of their tasks, with 19% potentially seeing over half impacted (Eloundou et al., 2023).\nUsage data from Anthropic indicates that in early 2025, at least some workers in 36% of occupations\nalready were using AI for at least 25% of their tasks (Handa et al., 2025).\nWhile AI adoption in the workplace has shown promise in boosting productivity, it also raises con-\ncerns about job displacement, reduced human agency, and overreliance on automation (Hazra et al.,\n\n*Equal Contribution\n\n1\n\nhttps://arxiv.org/abs/2506.06576v2\n\n\n2025). Despite this critical impact, we lack a systematic and grounded understanding of the evolving\nlandscape. From a coverage perspective, prior research often focuses on a few domains like software\nengineering (Hoffmann et al., 2024) and customer support (Brynjolfsson et al., 2025). This narrow scope\nlimits our comprehension of the real-world complexity of diverse human jobs and the varied nature\nof open-ended tasks. From a stakeholder perspective, existing studies often emphasize the interests of\ncapital by focusing on a few tasks that tend to be more profitable such as coding without adequately\nconsidering worker values (Eisfeldt et al., 2023). Furthermore, current approaches often rely on analyz-\ning existing usage data, such as how people use chatbots for work (Hazra et al., 2025, Zhao et al., 2024),\nwhich cannot provide a forward-looking assessment of AI potential across the broader workforce.\nTo address these gaps, we propose a principled, survey-based framework to investigate which occupa-\ntional tasks workers want AI agents to automate or augment. We look at the entire workforce that could\nbe impacted by digital AI agents by sourcing occupational tasks from the U.S. Department of Labor’s\nO*NET database. Compared to occupation-level studies, task-level auditing allows us to better capture\nthe nuanced, open-ended, and contextual nature of real-world work. Our auditing framework takes\na worker-centric approach by soliciting first-hand insights from domain workers actively performing\nthe tasks. To guide domain workers in providing well-calibrated responses, we empower them to share\ntheir experiences and articulate their reasoning through an audio-enhanced survey system. Crucially,\nour framework expands beyond the binary view of automation. We propose the Human Agency Scale\n(i.e., H1-H5), which complements the SAE L0-L5 automation levels (Committee et al., 2014) by quantify-\ning the degree of human involvement required for occupational task completion and quality. This new\nscale centers human agency—a crucial factor for responsible AI agent adoption (Fanni et al., 2023)—\nand provides a shared language to capture the spectrum between automation and augmentation.\nTo ground workers’ perspectives in technical reality, we further gather complementary assessments\nfrom AI experts with experience in agent research and development (R&D). This dual approach\nreveals how workers and experts perceive AI agents’ capabilities and risks at work. Based on data\ncollected through January 2025 to May 2025, we construct the AI Agent Worker Outlook & Readiness\nKnowledge Bank (WORKBank). This database currently consists of responses from 1,500 workers\nacross 104 occupations and annotations from 52 AI experts, covering 844 occupational tasks. It is\ndesigned to be easily extensible to more tasks and to reflect evolving technological capabilities and\nworker preferences. To our knowledge, this is the first large-scale audit of AI agent capabilities and\nworker preferences.\nOur work contributes four sets of findings:\n\n1. Domain workers want automation for low-value and repetitive tasks (Figure 4). For 46.1%\nof tasks, workers express positive attitudes toward AI agent automation, even after reflecting\non potential job loss concerns and work enjoyment. The primary motivation for automation is\nfreeing up time for high-value work, though trends vary significantly by sector.\n\n2. We visualize the desire-capability landscape of AI agents at work, and find critical mismatches\n(Figure 5). The worker desire and technological capability divide the landscape into four zones:\nAutomation “Green Light” Zone (high desire and capability), Automation “Red Light” Zone\n(high capability but low desire), R&D Opportunity Zone (high desire but currently low capabil-\nity), and Low Priority Zone (low desire and low capability). Notably, 41.0% of Y Combinator\ncompany-task mappings are concentrated in the Low Priority Zone and Automation “Red\nLight” Zone. Current investments mainly center around software development and business\nanalysis, leaving many promising tasks within the “Green Light” Zone and Opportunity Zone\nunder-addressed.\n\n2\n\n\n\n3. The Human Agency Scale provides a shared language to audit AI use at work and reveals\ndistinct patterns across occupations (Figure 6). 45.2% of occupations have H3 (equal partnership)\nas the dominant worker-desired level, underscoring the potential for human-agent collaboration.\nHowever, workers generally prefer higher levels of human agency, potentially foreshadowing\nfriction as AI capabilities advance.\n\n4. Key human skills are shifting from information processing to interpersonal competence\n(Figure 7). By mapping tasks to core skills and comparing their associated wages and required\nhuman agency, we find that traditionally high-wage skills like analyzing information are becom-\ning less emphasized, while interpersonal and organizational skills are gaining more importance.\nAdditionally, there is a trend toward requiring broader skill sets from individuals. These patterns\noffer early signals of how AI agent integration may reshape core competencies.\n\n2 Auditing Framework\n\nTo investigate how AI agents may integrate into professional work, we develop a task-level,\nsurvey-based auditing framework that captures both worker preferences and technological feasibility\nacross the automation–augmentation spectrum. We begin by outlining a few key design principles\nof our framework before examining each one in detail.\n\n2.1 Defining Audit Granularity and Scope\n\nOur framework focuses on complex, multi-step tasks associated with specific occupations (e.g.,\n“Marketing Managers: Compile lists describing product or service offerings”), sourced from the\nO*NET database. These tasks, unlike isolated, low-level activities (e.g., “track goods or materials”\nor “translate information”), reflect actual job responsibilities and the kinds of workflows AI agents\nare poised to impact. Moreover, compared with occupation-level analysis, conducting the audit at\nthe task level enables a more nuanced understanding, as tasks within the same profession can vary\nsignificantly and are often highly contextualized.\nWe scope our audit to computer-compatible tasks, recognizing their susceptibility to foundation model-\npowered AI agents. Drawing from historical and recent literature on agent autonomy (Castelfranchi,\n1994, Russell and Norvig, 1995, Wooldridge and Jennings, 1995), planning capabilities, and tool\nuse (Mitchell et al., 2025), we define AI agents (excluding physical robots) as: “A system or program\ncapable of autonomously performing tasks on behalf of a user or another system by designing its workflow and\nutilizing available software tools, without the ability to perform physical actions.”\n\n2.2 Emphasizing the Spectrum of Automation and Augmentation\n\nTraditional technology impact studies often ask: To what degree can this task be automated? Besides this\nview of automation, we consider the view of augmentation—where technology complements and\nenhances human capabilities (Autor, 2015), as this new wave of technology holds significant potential\nto augment human workers through human-agent collaboration, enhancing both productivity and\nwork quality. While augmentation has been discussed in prior work (Brynjolfsson, 2022, Handa et al.,\n2025), there is no established framework for quantifying automation vs. augmentation. To fill this gap\nand provide a shared language, we introduce the Human Agency Scale (HAS) (Figure 2), a five-level\nscale from H1 (no human involvement) to H5 (human involvement essential):\n\n• H1: AI agent handles the task entirely on its own.\n• H2: AI agent needs minimal human input for optimal performance.\n\n3\n\n\n\nPotential Shift in\nCore Human Skills\n\nAutonomous Agent\nDesire-Capability Landscape\n\nSystematicity of \nWorker-centered Needs\n\nAugmentation\n\nJob Security\n\nEnjoyment\n\nPhysical Action\n\nDomain Expertise\n\nUncertainty\n\nInterpersonal\nCommunication\n\nAutomation\n\nTo what extent do current AI \nsystems support automating this \ntask?\n\nIf an AI system can do this task for \nyou completely, how much do you \nwant it to do it for you?\n\nIf an AI system were to assist in this\ntask, how much collaboration\nbetween workers and the AI system\nwould be needed to complete this\ntask effectively?\n\nIf an AI system were to assist in this \ntask, how much collaboration\nbetween you and the AI system \nwould be needed to complete this \ntask effectively?\n\nAuditing Framework With Audio Interface\n\nWORKBank\n\nFindings\n\n52 AI Experts\n\n1,500 Domain Workers\nAcross 104 Occupations\n\n2,131 Tasks\nPerformable on Computers\n\nFilter Occupations Filter Tasks\n\nCompliance Officers: Issue licences to individuals\nmeeting standards.\n\nCustoms Brokers: Monitor or trace the location of\ngoods.\n\nFundraisers: Write and send letters of thanks \nto donors.\n\nHuman Agency Scale\nSpectrum\n\nOccupational Task Rank\n\nAu\nto\n\nm\nat\n\nio\nn \n\nD\nes\n\nire\n\nAu\nto\n\nm\nat\n\nio\nn \n\nD\nes\n\nire\n\nTechnological Capability\n\n1. Schedule appointments with clients\n2. Maintain files of information...\n3. Issue and record adjustments to...\n\nHuman Agency Scale (HAS)\n\nR\nat\n\nin\ng \n\nP\ner\n\nce\nnt\n\nag\ne\n\nH1 H2 H3 H4 H5\n\nWorker Desire\n\nAI Expert\nAssessment\n\nComputer Programmers\n\n842. Write stories\n843. Contact potential vendors to...\n844. Trace lost baggage for customers\n\nWage Human\nAgency\n\nAnalyzing Information\n\nTraining, Teaching Others\n\nDocumenting Information\n\nFigure 1: Overview of the auditing framework and key insights. The framework captures dual\nperspectives on automation and augmentation by eliciting both worker desires and expert assessments\nof technological capabilities. It guides participant reasoning through structured prompts and an\naudio-enhanced interface. We instantiate this framework to build the WORKBank database, enabling\na data-driven analysis of worker-centered needs, the desire–capability landscape, the Human Agency\nScale (HAS) spectrum, and implications for core human skills.\n\n• H3: AI agent and human form equal partnership, outperforming either alone.\n• H4: AI agent requires human input to successfully complete the task.\n• H5: AI agent cannot function without continuous human involvement.\n\nUnlike SAE driving automation levels (Committee et al., 2014) that adopt an “AI-first” perspective,\nHAS provides a human-centered lens for assessing both task properties and appropriate agent develop-\nment approaches. Importantly, higher HAS levels are not inherently better—different levels suit differ-\nent AI roles. Tasks at H1-H2 favor automation approaches, while H3-H5 tasks benefit from augmenta-\ntion strategies. Understanding the ideal level of human involvement is essential both for workers seek-\ning to adapt their skills and for developers aiming to build context-appropriate AI agents. For instance,\n\n4\n\n\n\nAI Agent Drives Task Completion\nThe AI agent takes primary reponsibility for task \nexecution with no or minimal human oversight.\n\nHuman Drives Task Completion\nThe human takes primary responsibility for task \nexecution with varying levels of AI assistance.\n\nEqual Partnership\nThe human and the AI \n\nagent collaborate closely \nthroughout the task.\n\nTeam \nDynamics\n\nAutomation\nAI replaces human capabilities\n\nAugmentation\nAI enhances human capabilities\n\nAI Role\n\nAI agent handles the \ntask entirely on its own \n\nwithout your \ninvolvement.\n\nAI agent needs your \ninput at a few key \n\npoints to achieve better \ntask performance.\n\nTask completion fully \nrelies on your \ninvolvement.\n\nAI agent and you work \ntogether to outperform \n\neither alone.\n\nRequired \nHuman \n\nInvolvement\n\nAI agent needs your \ninput to successfully \ncomplete the task.\n\nExample \nTasks\n\n• Transcribe data to \nworksheets and \nenter data into \ncomputer.\n\n• Run monthly \nnetwork reports.\n\n• Devise trading, \noption, or hedge \nstrategies.\n\n• Accept payment on \naccounts.\n\n• Create core game \nfeatures, including \nstorylines, role-play \nmechanics, etc.\n\n• Compile and analyze \nexperimental data \nand adjust \nexperimental \ndesigns as necessary.\n\n• Coordinate and \ndirect the financial \nplanning, budgeting, \nprocurement, or \ninvestment activities.\n\n• Design, plan, \norganize, or direct \norientation and \ntraining programs.\n\n• Participate in online \nforums or \nconferences to stay \nabreast of online \nretailing trends, \ntechniques, or \nsecurity threats.\n\nHAS H1 HAS H2 HAS H3 HAS H4 HAS H5\n\nFigure 2: Levels of Human Agency Scale (HAS). We introduce the Human Agency Scale (i.e., H1-\nH5) to quantify the team dynamics and degree of human involvement required. HAS provides a\nshared language to quantify automation vs. augmentation, complementing the traditionally “AI-first”\nperspective used in defining levels of automation. Importantly, higher HAS levels are not inherently\nbetter—different levels suit different AI roles.\n\nfully autonomous agents shall be developed for H1 scenarios, while those agents for H3 scenarios must\nsupport meaningful coordination and communication with human collaborators (Shao et al., 2024b).\nThis five-level human agency scale (H1-H5) helps categorize tasks where AI is more suitable for\nautomation (H1-H2) versus augmentation (H3-H5), where human agency remains critical.\n\n2.3 Constructing A Worker-Centric Auditing Framework\n\nOur auditing framework centers on the needs of workers. To support domain workers in providing\nwell-calibrated feedback, we enable them to share their experiences and explain their thought\nprocesses using an audio-supported survey system. Concretely, for each task t, we first collect worker\nratings on automation desire Aw(t) and desired HAS level Hw(t) using a 5-point Likert scale.\n\nLikert Question for Collecting Automation Desire\n\nIf an AI system can do this task for you completely, how much do you want it to do it for you?\n1: Not at all; 2: Slightly; 3: Moderately; 4: A lot; 5: Entirely\n\n5\n\n\n\nLikert Question for Collecting Desired HAS Level\n\nIf an AI system were to assist in this task, how much collaboration between you and the AI system would be needed\nto complete this task effectively?\n1: No Collaboration Needed (Human Agency Scale H1);\n2: Limited Collaboration Needed (Human Agency Scale H2);\n3: Moderate Collaboration Needed (Human Agency Scale H3);\n4: Considerable Collaboration Needed (Human Agency Scale H4);\n5: Essential Collaboration Needed (Human Agency Scale H5)\n\nTo support thoughtful ratings, we also scaffold worker responses through three key designs (survey\ndetails in Appendix A):\n\n• Audio-enhanced Reflection: The survey begins with an audio-enhanced mini-interview ex-\nploring participants’ occupational work and AI perspectives. This spoken format enables more\nnatural reflection and helps workers more efficiently contextualize their ratings within their\nactual work experience, compared to slowly typing their experiences.\n\n• Quality Control via Task Familiarity Filtering: Workers receive only occupation-relevant tasks\nand must confirm task familiarity before rating, ensuring assessments are grounded in their real\nexperience rather than speculation.\n\n• Guided Consideration: Before rating both automation desireAw(t) and desired HAS levelHw(t),\nparticipants consider factors identified in prior literature—enjoyment and job security concerns\nfor automation desire (Armstrong et al., 2024, Gödöllei and Beck, 2023), and task characteristics\nlike physical actions, domain expertise requirements, uncertainty, and interpersonal elements\nfor HAS preferences (Frank et al., 2019, Parasuraman, 2000, Shah and White, 2024).\n\n2.4 Ensuring Dual Perspectives from Both Domain Workers and AI Experts\n\nWhile worker perspectives provide invaluable insights into the social demand and acceptance of\nAI agents, they represent only one side of the integration equation. Domain workers, despite their\ndeep task expertise, may have limited exposure to current AI capabilities and constraints. Thus,\nwe complement workers’ perspectives with expert assessments of current automation capability Ae(t)\nand feasible HAS level He(t) from AI researchers and practitioners. This dual perspective reveals the\nreadiness for AI agent integration and allows us to identify alignment or gaps between worker desires\nand technological feasibility.\nConcretely, these experts assess Ae(t) and He(t) using the same rubrics, drawing on their under-\nstanding of existing systems’ strengths and limitations. Contrasting Aw(t), Hw(t) and Ae(t), He(t)\nenables us to understand what require future breakthroughs, identify alignments and misalignments\nbetween worker preferences and technological development, and inform development priorities .\n\n2.5 Instantiating the Audit Framework to Derive WORKBank\n\nTaking into account these aforementioned design principles together, we then apply our auditing\nframework to develop Worker Outlook & Readiness Knowledge Bank (WORKBank). Concretely, we\nsource computer-compatible tasks performed at least monthly from the U.S. Department of Labor’s\nO*NET Database (details in Appendix C.1). These tasks reflect complex, multi-step workflows central\nto our focus. For example, the task “Credit Analysts: Analyze credit data and financial statements\nto determine the degree of risk involved in extending credit or lending money” entails data analysis,\nrisk evaluation, and decision-making. After filtering, 2,131 tasks across 287 occupations remain.\n\n6\n\n\n\na Coverage Amongst All US Workforce Sectors\n\nComputer and Mathematical\n\nBusiness and Financial Operations\n\nOffice and Administrative Support\n\nManagement\n\nArts, Designs, and Media\n\nArchitecture and Engineering\n\nLife Physical and Social Science\n\nSales and Related\n\nEducational Instruction and Library\n\nLegal\n\nHealthcare Practitioners and Technical\n\nHealthcare Support\n\nProduction\n\nFood Preparation and Serving*\n\nFarming Fishing and Forestry*\n\nInstallation Maintenance and Repair*\n\nConstruction and Extraction*\n\nPersonal Care and Service*\n\nCommunity and Social Service*\n\nCleaning and Maintenance*\n\nProtective Service*\n\nTransportation and Material Moving*\n\nb Coverage Amongst Sectors of Included Occupations\n\nComputer and Mathematical\n\nBusiness and Financial Operations\n\nOffice and Administrative Support\n\nManagement\n\nArts, Designs, and Media\n\nArchitecture and Engineering\n\nLife Physical and Social Science\n\nSales and Related\n\nEducational Instruction and Library\n\nLegal\n\nHealthcare Support\n\nHealthcare Practitioners and Technical\n\nProduction\n\n0% 25%5% 10% 15% 20% 0% 40%10% 20% 30%\n\nPercentage of Workers Percentage of Workers\n\nFigure 3: Sector-level distribution of workers in the WORKBank database compared to U.S.\nworkforce statistics from the Bureau of Labor Statistics. a, Comparison between WORKBank worker\ndistribution and the U.S. workforce employment statistics across all sectors (sectors not included in\nWORKBank marked with an asterisk). b, Comparison between WORKBank worker distribution and\nthe U.S. workforce employment statistics limited to the 104 occupations included in our database.\n\nWe developed an IRB-approved, self-hosted survey interface and distributed it through crowdsourc-\ning platforms and targeted LinkedIn outreach. Between January and May 2025, recruitment through\nProlific, Upwork, and LinkedIn yielded 1,676 participants who provided 7,016 task ratings. After\nfiltering for adequate representation (≥ 10 participants per occupation), we obtained assessments\nfrom 1,500 individuals across 104 occupations and calculated average worker ratings Aw(t) and\nHw(t) for each task. We evaluate the representativeness of WORKBank by comparing its sector-level\ndistribution with U.S. workforce data from the Bureau of Labor Statistics (Appendix D.2). As\nshown in Figure 3, the comparisons suggest that our database captures a broad and representative\ncross-section of the U.S. workforce at the sector level.\nFor expert assessments, we recruited 52 AI experts—PhD researchers and industry practitioners with\nexperience in AI agent R&D. Each task was independently assessed by at least two experts, with\nadditional reviews ensuring rating consistency (standard deviation ≤1). Inter-annotator agreement,\nmeasured by Krippendorff’s α, was 0.539 for Ae(t) and 0.511 for He(t) (see robustness analysis details\nin Appendix B).\nCombining these complementary data sources, we construct Worker Outlook & Readiness\nKnowledge Bank (WORKBank), the first database to capture both worker desires and AI agents’\ntechnological capabilities for occupational tasks.\n\n7\n\n\n\n3 Results\n\nLeveraging the rich data within WORKBank, we examine where workers most desire automation\nby AI agents and where they resist it, whether current AI capabilities and R&D align with these\npreferences, what opportunities exist for AI to augment rather than replace human labor, and how\nthe presence of AI agents might reshape the demand for human skills.\n\n3.1 Worker-centered Views on Occupational Task Automation\n\nComputer and Mathematical Management\n\nBusiness and Financial Operations Arts, Designs, and Media\n\n969 874 667\nAutomating the task would free up \n\nmy time for high-value work.\n\n605 573 508This task is repetitive or tedious.\n\n646 598 442\nAutomating this task would improve \n\nthe quality of my work.\n\n333 332 258\nThe task is stressful or mentally \n\ndraining.\n\n286 238 159This task is complicated or difficult.\n\na Automation Desire Score Over 844 Tasks Across 104 Occupations\n\nb Selected Reasons for Responses with Automation Desire (𝑨𝒘(𝒕)) ≥ 3 (N=3,618) \n\n𝐴𝑤(𝑡) = 5\n\n𝐴𝑤(𝑡) = 4\n\n𝐴𝑤(𝑡) = 3\n\n1.26%\n\nc Percentage of Usage on Claude.ai\n(Dec 2024–Jan 2025)\n\nTop 10 \nOccupations by \nAverage \nAutomation \nDesire\n\n1. Tax Preparers: Schedule appointments with clients.  \n𝐴𝑤 𝑡 = 5.00\n\n2. Public Safety Telecommunicators: Maintain files of \ninformation relating to emergency calls. 𝐴𝑤 𝑡 = 4.67\n\n3. Timekeeping Clerks: Issue and record adjustments to \npay related to previous errors. 𝐴𝑤 𝑡 = 4.60\n\n842. Editors: Write text, such as stories, articles, editorials, or \nnewsletters. 𝐴𝑤 𝑡 = 1.60\n\n843. Logistics Analysts: Contact potential vendors to \ndetermine material availability. 𝐴𝑤 𝑡 = 1.50\n\n844. Ticket Agents and Travel Clerks: Trace lost, delayed, or \nmisdirected baggage for customers. 𝐴𝑤 𝑡 = 1.50\n\nFigure 4: First-hand data from domain workers reveals positive attitudes towards AI agent au-\ntomation on certain occupational tasks, particularly due to perceived benefits such as freeing up\ntime for high-value work. However, the sentiment varies notably across sectors. a, Automation\ndesire scores Aw(t) over 844 occupational tasks, ranked based on WORKBank data, together with\nsector-specific breakdowns. The distribution indicates a mixed attitude, revealing high diversity of\nneeds and preferences of workers that should be considered in AI agent R&D. b, Reported reasons for\nresponses with Aw(t)≥3. The most selected reason—“Automating the task would free up my time\nfor high-value work”—accounts for 69.38% of the responses. c, Comparison with usage data from\nClaude.ai, a LLM-based chatbot (Dec 2024-Jan 2025, from Handa et al. (2025)), shows that the top 10\noccupations with the highest average automation desire represent only 1.26% of total usage. This\nhighlights the importance of directly soliciting worker input, as usage data may lag behind actual\nworkplace needs.\n\n8\n\n\n\nWhere do workers desire AI agent automation? We first examine domain workers’ attitudes\ntoward automating their occupational tasks. In Figure 4 a, we rank tasks by their average worker\nautomation desire scores Aw(t). We find that for 46.1% of tasks, workers currently performing\nthem express a positive attitude (i.e., Aw(t)> 3) toward AI agent automation, even after explicitly\nconsidering concerns such as job loss and reduced enjoyment, as guided by our auditing framework.\nOn the other hand, the distribution indicates a mixed attitude, with 7.11% tasks receiving Aw(t)≥4\nand 6.16% receiving Aw(t)≤2. To better understand these preferences, Figure 4 b aggregates selected\nreasons given for pro-automation responses (Aw(t)≥ 3). The most cited motivation—“freeing up\ntime for high-value work”—was selected in 69.38% of cases. Other common reasons include task\nrepetitiveness (46.6%), stressfulness (25.5%), and opportunities for quality improvement (46.6%).\nThe overall pattern suggests that AI agents could play a supportive role, enabling workers to offload\nlow-value or burdensome tasks, rather than serving as replacements in a zero-sum dynamic.\n\nDoes existing LLM usage reflect worker desires? Notably, when we compare our findings with\nusage data from Claude.ai, an LLM-based chatbot used between Dec 2024 and Jan 2025 (Handa et al.,\n2025), we find that the top 10 occupations with the highest average automation desire account for\nonly 1.26% of total usage. This mismatch highlights a disconnect: occupations where workers most\ndesire automation are currently underrepresented in LLM usage. This suggests that existing usage\npatterns may be skewed toward early adopters or specific job types, rather than reflecting broader\ndemand. Such a gap reinforces the value of our worker-centric audit, which surfaces latent needs\nthat may not yet appear in usage logs.\n\nWhere do workers resist AI agent automation? We analyze audio response data using LLM-based\ntopic modeling to identify the primary concerns workers expressed regarding the use of AI agents\nin their work (see Appendix F.1). Among our survey participants, 28.0% expressed fears, concerns,\nor negative sentiment when answering the question “How do you envision using AI in your daily\nwork?”. Among these workers, the three most prominent concerns identified are: (1) lack of trust\nin AI systems’ accuracy, capability, or reliability (45.0%), (2) fear of job replacement (23.0%), and (3)\nthe absence of human qualities or capabilities in AI (16.3%).\nWhen discussing the absence of human qualities, workers express specific concerns about losing\na “human touch” in their work, diminishing creative control, and the desire to maintain agency in\ndecision-making. This sentiment echoes our quantitative findings from the breakdown of automation\ndesire scores across sectors (Figure 4 a). In these sector-level breakdowns, the “Arts, Designs,\nand Media” sector stands out, with only 17.1% of tasks receiving positive desire ratings (> 3 on a\n5-point Likert scale). Audio responses from participants in this sector reveal nuanced opposition\nto automating content creation, such as: “I want it to be used for seamlessly maximizing workflow and,\nyou know, making things less repetitive and tedious and arduous with workflow. No content creation,” “I would\nnever use AI to like replace artists. I would be more for personal [project management] use, if anything,” “AI\ncan be a game-changer in data architect workflow, helping to improve efficiency, accuracy and even creativity.\nBut I create my design by myself. For research, I use AI”.\n\n3.2 Desire-Capability Landscape for AI Agents in the Workplace\n\nContrasting worker and AI expert perspectives delineate four task zones. While workers’\npreferences offer valuable guidance for socially beneficial AI agent deployment, delivering impact ul-\ntimately depends on aligning those preferences with technical feasibility. To investigate this, we jointly\nconsider the worker-rated automation desire Aw(t) and expert-assessed technological capability\nAe(t), visualized as a desire-capability landscape in Figure 5 a. This landscape divides into four zones:\n\n9\n\n\n\nAutomation “Green Light” Zone\n\nAutomation “Red Light” Zone\n\nR&D Opportunity Zone\n\nLow Priority Zone\n\nTax Preparers: \nSchedule \n\nappointments \nwith clients.\n\nQuality Control \nSystem Mangers: \nCheck regularly \nreported quality \ncontrol data.\n\nMechanical \nEngineers:\nRead and \ninterpret reports.\n\nLogistics Analysts: \nContact potential \nvendors to \ndetermine material \navailability.\n\nCourt, Municipal \nClerks: Prepare \nmeeting agendas\n\nComputer \nNetwork \nSupport \nSpecialists: \nResearch \nhardware or \nsoftware \nproducts.\n\nComputer \nScientists: \nApprove, \nprepare monitor, \nand adjust \noperational \nbudgets.\n\nVideo Game \nDesigners: \nCreate \nproduction \nscheduels, \nprototyping \ngoals with \nproduction \nstuffs.\n\nTechnical \nWriters: \nArrange for \ndistribution \nof material.\n\nMedia \nTechnical \nManagers: \nObserve \npictures \nthrough \nmonitors.\n\nArt Directors: \nPresent final \nlayouts to \nclients.\n\nTicket Agents: \nTrace lost, delayed, \nor midirected \nbaggages for \ncustomers.\n\na Automation Desire-Capability Landscape\n\nb Average Number \nof Y Combinator \nCompanies per Task \nby Desire–\nCapability Zone\n(Cut-off Date:\nApril 28, 2025)\n\n134.35\n\n117.63\n\n118.87\n\n134.57\n\n120.70\n\n170.89\n\n118.08\n\n106.32\n\nComputer and Mathematical Management\n\nBusiness and Financial Operations Arts, Designs, and Media\n\n47.4%13.3%\n\n13.3% 25.4%\n\n42.4%18.5%\n\n8.7% 30.4%\n\n51.2%7.6%\n\n10.6% 30.6%\n\n9.8%11.0%\n\n31.7% 47.6%\n\nc  Average Number \nof AI Agent \nResearch Papers \nper Task by Desire–\nCapability Zone\n(Cut-off Date:\nApril 24, 2025)\n\nFigure 5: Integrating worker and AI expert perspectives divides the automation landscape into four\nzones: Automation “Green Light” Zone, Automation “Red Light” Zone, R&D Opportunity Zone,\nand Low Priority Zone. a, Tasks from WORKBank are plotted in this desire-capability landscape.\nb, We collect Y Combinator (YC) companies and map them to tasks based on the description on\ntheir official YC detail pages using gpt-4.1-mini. The average number of YC companies per task\nshows no significant difference across zones, highlighting the importance of steering more investment\ntoward the Automation “Green Light” Zone and R&D Opportunity Zone. c, We collect AI agent\nresearch papers from arXiv and evaluate their applicability to each occupational task in our database\nusing gpt-4.1-mini. Encouragingly, the paper-task mappings are concentrated more in the R&D\nOpportunity Zone, though increased emphasis on this area remains desirable.\n\n1. Automation “Green Light” Zone: Tasks with both high automation desire and high capability.\nThese are prime candidates for AI agent deployment with the potential for broad productivity\nand societal gains.\n\n2. Automation “Red Light” Zone: Tasks with high capability but low desire. Deployment here\nwarrants caution, as it may face worker resistance or pose broader negative societal implications.\n\n3. R&D Opportunity Zone: Tasks with high desire but currently low capability. These represent\npromising directions for AI research and development.\n\n4. Low Priority Zone: Tasks with both low desire and low capability. These are less urgent for AI\nagent development.\n\nTasks from WORKBank are broadly distributed across the landscape, with no strong correlation\nbetween Aw(t) and Ae(t) (Spearman ρ=0.17, p<1e−6). Overall, automation desire shows a negative\n\n10\n\n\n\ncorrelation with both job loss concern (Spearman ρ=−0.223, p<5e−11) and enjoyment (Spearman\nρ=−0.284, p<3e−17). This suggests both alignments and misalignments between worker desires\nand technological capabilities, with a consistent pattern: workers are less inclined to have AI agents\nautomate tasks they enjoy or feel vulnerable about potential job loss, consistent with findings from\nprior literature (Armstrong et al., 2024, Gödöllei and Beck, 2023).\n\nMapping investment to the desire-capability landscape reveals critical mismatches. To better\nunderstand where current investments are concentrated, we used Y Combinator (YC) companies1\n\nas a proxy and mapped them to the tasks in our database using gpt-4.1-mini (one company\ncould be mapped to multiple tasks, see Appendix C.4 for details). As shown in Figure 5 b, the\ncompany-task mappings are relatively evenly spread across the four zones. Most mapped tasks are\nconcentrated in occupations related to software development and business analysis, with the top\nfive occupations being: Computer and Information Systems Managers, Computer Programmers,\nComputer Systems Engineers/Architects, Software Quality Assurance Analysts and Testers, and\nBusiness Intelligence Analysts. 41.0% of YC companies are mapped to Low Priority and Automation\n“Red Light” Zone; while many promising tasks within the “Green Light” Zone and Opportunity Zone\nremain under-addressed by current investments.\n\nAI agent research papers show an emphasis on the R&D Opportunity Zone, but remain concentrated\non a limited set of tasks. Following a similar methodology, we gathered research papers related to\nAI agents from arXiv2 and analyzed their alignment with various tasks to determine the distribution of\nresearch efforts. Figure 5 c shows that research papers are more concentrated in the R&D Opportunity\nZone. While encouraging, the focus remains largely confined to computer science and engineering\ndomains. The top three tasks covered are: (1) Computer and Information Research Scientists: Apply\ntheoretical expertise and innovation to create or apply new technology, such as adapting principles\nfor applying computers to new uses (1,169 papers); (2) Computer and Information Research Scientists:\nAnalyze problems to develop solutions involving computer hardware and software (1,132 papers);\n(3) Computer Programmers: Perform or direct revision, repair, or expansion of existing programs to\nincrease operating efficiency or adapt to new requirements (1,109 papers). These findings highlight the\nneed to expand research efforts beyond a few domains to better support tasks in the R&D Opportunity\nZone, ensuring that future AI agents address a wider range of high-desire, high-impact opportunities.\n\n3.3 Human Agency Scale (HAS) Spectrum\n\nBeyond automation, AI agents hold promise for augmenting human work. To understand where and\nhow this augmentation may occur, we analyze the distribution of both worker-desired HAS levels\n(Hw(t)) and expert-assessed feasible HAS levels (He(t)) across tasks within each occupation.\n\nWhere do worker desires and expert assessments diverge most on the Human Agency Scale?\nEach task in WORKBank is assigned a worker-desired and expert-rated HAS level via majority vote.\nAmong 844 tasks, 26.9% receive matching levels from workers and AI experts. Figure 6 a shows work-\ners generally prefer higher levels of human agency than what experts deem technologically necessary,\nwith 47.5% of tasks fall into the lower triangle of the matrix. To quantify this divergence, we compute\nthe Jensen-Shannon Distance (JSD) between the distributions of Hw(t) and He(t) at the occupation\nlevel. Disagreements are most pronounced in the lower HAS range as Table 5 shows that five of\nthe ten occupations with the highest JSD scores are also those that experts rate as H1 dominant.This\n\n1https://www.ycombinator.com/companies\n2http://arxiv.org\n\n11\n\nhttps://www.ycombinator.com/companies\nhttp://arxiv.org\n\n\na Distribution of Tasks by Worker-Desired and \nExpert-Assessed Feasible HAS Levels\n\nPhysical Action\n\nUncertainty\n\nDomain\nExpertise\n\nInterpersonal\nCommunication\n\nc Task Characteristics by Worker Ratings d Task Characteristics by AI Expert Ratings\n\nTasks in H5 by \nWorker Desire\nAll Occupations\n\nTasks in H5 by \nExpert Assessment\nAll Occupations\n\nb Percentage of Occupations Grouped by \nDominant Worker-Desired HAS Level\n\nH1\nH2\n\nH3\nH4\n\nH5\n\nWorker-Desired \nLevel\nExpert-Rated \nFeasible Level\n\nPhysical Action\n\nUncertainty\n\nDomain\nExpertise\n\nInterpersonal\nCommunication\n\nH1: 1.9%\n\nH2: 35.6%\n\nH3: 45.2%H4: 16.3%\n\nH5: 1.0%\n\n32\n\n112\n\n61\n\n19\n\n1\n\n34\n\n102\n\n114\n\n41\n\n5\n\n30\n\n63\n\n71\n\n30\n\n11\n\n7\n\n36\n\n34\n\n22\n\n7\n\n0\n\n4\n\n7\n\n1\n\n0\n\nFigure 6: Distributions on the Human Agency Scale (HAS) reveal diverse patterns of AI agent\nintegration across occupations and underscore opportunities for human–agent collaboration. a,\nComparison between worker-desired HAS levels (Hw(t)) and expert-assessed feasible HAS levels\n(He(t)) shows that workers generally prefer higher levels of human agency than what experts deem\ntechnologically necessary. b, Distribution of occupations by their dominant worker-desired HAS\nlevel shows that most occupations cluster around H3 and helps identify occupations that are at the\npoles of the agency spectrum. Each subplot displays the task-level distributions of worker-desired\nand expert-assessed HAS levels for a given occupation. Jensen-Shannon divergence (JSD) quantifies\nthe difference between these distributions (see top 10 in Table 5). Full occupation-level results are\nshown in Figure 10. c, Radar plot of task characteristics based on worker ratings indicates that tasks\nin the H5 region are particularly associated with Interpersonal Communication. d Radar plot based\non expert ratings shows that tasks in H5 are marked by strong Interpersonal Communication and\nDomain Expertise components.\n\nsignals potential frictions as AI adoption progresses. Ensuring socially responsible deployment of\nAI agents and supporting workers currently performing low-HAS tasks warrant further scrutiny.\n\nWhat are the common patterns across the Human Agency Scale spectrum? As illustrated in\nFigure 6 b (with full results in Figure 10), many occupations (e.g., “Sustainability Specialists”, “Energy\nEngineers”) exhibit an inverted-U shaped distribution for both Hw(t) and He(t). While this trend in\nexpert assessments might reflect current technological limitations—i.e., AI agents are not yet capable\nof fully replacing human involvement in most tasks—it is notable that workers in many domains also\nprefer a balanced, collaborative partnership with AI. H3 emerges as the dominant worker-desired\nlevel in 47 out of 104 occupations analyzed.\n\n12\n\n\n\nWhich occupations stand out on the Human Agency Scale? Beyond the general inverted-U trend,\nwe examine occupations at the extremes of the HAS spectrum. Lower HAS levels signify areas\nof greater potential AI exposure. According to AI experts’ ratings, 16 out of 104 occupations are\npredominantly H1, even based on current capability estimates. These include roles such as “Computer\nProgrammers”, “Proofreaders and Copy Makers”, and “Travel Agents”. Occupations within the\nsame sector also exhibit distinct trends in HAS levels. For example, “Computer Programmers” and\n“Information Technology Project Managers” display markedly different distributions (H1 vs. H4)\nwhen assessed by AI experts. Compared to Eloundou et al. (2023), which provides an early analysis\nof LLMs’ labor market impact and finds higher-wage occupations to be more exposed, our results\nshow that while most occupations in WORKBank are indeed exposed to AI agents and do not fall into\nH5 (essential human involvement), those involving more routine tasks and easily verifiable outcomes\ntend to require lower human agency.\nVery few occupations are characterized by a dominant HAS Level 5 (indicating essential human\ninvolvement). “Editors” is the only occupation where workers predominantly desire H5. According\nto AI expert assessments, only “Mathematicians” and “Aerospace Engineers” fall into this category.\nRepresentative work descriptions from worker transcripts for these occupations are provided in\nAppendix F.2. We further investigate what distinguishes H5 tasks. Among the four quantitative\ndimensions in our auditing framework (Figure 1), worker ratings highlight Interpersonal Communi-\ncation as a defining feature of H5 tasks (Figure 6 c), while expert ratings emphasize both Interpersonal\nCommunication and Domain Expertise (Figure 6 d).\n\nWhat forms of human-agent collaboration do workers envision? Figure 6 b suggests strong poten-\ntial for collaborative AI. Our analysis of audio transcripts supports this: the vast majority of workers\nexpress either a desire or openness to collaborating with AI to enhance their work. Analyzing these\nnarratives further illustrates how workers concretely envision human–agent partnerships. The most\ncommon paradigm is “role-based” AI support (described by 23.1% of workers), where individuals\nanticipate utilizing AI systems that embody specific roles or personalized functions (“[I would like to have\nan AI agent] trained to automatically analyze the quality control reports of raw sequencing data (e.g., FastQC\noutput) and flag potential issues with specific samples or sequencing runs, [...] and suggesting appropriate pre-\nprocessing steps.” “It’s just for me to set up my AI.”). Furthermore, 23.0% of workers express a desire for\nAI systems to function as a supportive assistant for some or all aspects of their workflow (“[I envision\nthe AI agent] as an assistant who is doing research for me. However, I review every answer because we cannot\nrely on its accuracy.”), while 16.5% mention pure automation by AI for some aspects of their workflow.\n\n3.4 The Potential Shift of Core Human Skills\n\nVariation in Human Agency Scale (HAS) across occupations suggests that certain types of human\nwork are more susceptible to automation, while others hold greater potential for augmentation. To\nthis end, we examine the characteristics of tasks that require high human agency to understand how\nAI agents may shift skill demands.\nTranslating task-level changes into implications for education and skill training has long been a key\nlens for analyzing technological transformation, notably pioneered by Autor et al. (2003) in the wave\nof computers. To operationalize this lens, we align each task with its related skills (Generalized Work\nActivities) as defined by O*NET (Appendix E.6). For example, the task “Financial Managers: Approve,\nreject, or coordinate the approval or rejection of lines of credit or commercial, real estate, or personal\nloans” will be mapped to “making decisions and solving problems” and “guiding, directing, and moti-\nvating subordinates”. We compute the average expert-assessed human agency levelHe(t) for each skill\nto estimate the degree of human involvement required as AI agents enter the workplace. We also com-\n\n13\n\n\n\nAnalyzing Data or Information\n\nUpdating and Using Relevant Knowledge\n\nDeveloping Objectives and Strategies\n\nGuiding, Directing, and Motivating Subordinates\n\nJudging the Qualities of Objects, Services, or People\n\nStaffing Organizational Units\n\nThinking Creatively\n\nMonitoring Processes, Materials, or Surroundings\n\nProviding Consultation and Advice to Others\n\nMaking Decisions and Solving Problems\n\nOrganizing, Planning, and Prioritizing Work\n\nCommunicating with Supervisors, Peers, or Subordinates\n\nInterpreting the Meaning of Information for Others\n\nDocumenting/Recording Information\n\nGetting Information\n\nSelling or Influencing Others\n\nEvaluating Information to Determine Compliance\n\nPerforming Administrative Activities\n\nEstablishing and Maintaining Relationships\n\nProcessing Information\n\nTraining and Teaching Others\n\nCommunicating with People Outside the Organization\n\nEstimating the Quantifiable Characteristics of Products\n\nPerforming for or Working Directly with the Public\n\nMonitoring and Controlling Resources\n\nAssisting and Caring for Others\n\nScheduling Work and Activities\n\nAnalyzing Data or Information\n\nUpdating and Using Relevant Knowledge\n\nDeveloping Objectives and Strategies\n\nGuiding, Directing, and Motivating Subordinates\n\nJudging the Qualities of Objects, Services, or People\n\nStaffing Organizational Units\n\nThinking Creatively\n\nMonitoring Processes, Materials, or Surroundings\n\nProviding Consultation and Advice to Others\n\nMaking Decisions and Solving Problems\n\nOrganizing, Planning, and Prioritizing Work\n\nCommunicating with Supervisors, Peers, or Subordinates\n\nInterpreting the Meaning of Information for Others\n\nDocumenting/Recording Information\n\nGetting Information\n\nSelling or Influencing Others\n\nEvaluating Information to Determine Compliance\n\nPerforming Administrative Activities\n\nEstablishing and Maintaining Relationships\n\nProcessing Information\n\nTraining and Teaching Others\n\nCommunicating with People Outside the Organization\n\nEstimating the Quantifiable Characteristics of Products\n\nPerforming for or Working Directly with the Public\n\nMonitoring and Controlling Resources\n\nAssisting and Caring for Others\n\nScheduling Work and Activities\n\nRanked by Average Wage\n(U.S. Bureau of Labor Statistics May 2024)\n\nRanked by Average Required Human Agency\n(WORKBank AI Expert Assessments)\n\nLow\n\nHigh\n\nWage\n\nLow\n\nHigh\n\nHuman\nAgency\n\nFigure 7: Comparing skill rankings by average wage and required human agency. Each line\nrepresents a skill (Generalized Work Activity) mapped from O*NET tasks. Based on the skill-task\nmapping, we compute the average wage using data from the U.S. Bureau of Labor Statistics (May\n2024) and the average expert-assessed human agency level He(t) to indicate the degree of human\ninvolvement required as AI agents enter the workplace. Skills are ranked by average wage (left)\nand average required human agency (right). The figure highlights the top five skills with the largest\nupward (green) and downward (red) shifts in rank, suggesting a potential shift in valued workplace\nskills—from information processing toward interpersonal and organizational competencies. See\nAppendix E.6 for skill analysis details and full skill descriptions.\n\npute the average wage for each skill, using data from the U.S. Bureau of Labor Statistics (Appendix C.2).\nWage serves as a proxy for the current economic value of each skill (Dey and Loewenstein, 2019).\nAs shown in Figure 7, by comparing skill rankings by average wage and required human agency,\nour analysis reveals three emerging trends:\n\n14\n\n\n\n1. Shrinking demand for information-processing skills. Skills related to analyzing data and\nupdating knowledge—while common in today’s high-wage occupations (as shown in the left\nside of Figure 7 in red color)—are less prominent in tasks that demand high human agency.\n\n2. Greater emphasis on interpersonal and organizational skills. Skills involving human interac-\ntion, coordination, and resource monitoring are more frequently associated with high-HAS tasks\n(as shown in the left side of Figure 7 in green color), even if they are not currently prioritized in\nwage-based evaluations.\n\n3. High-agency skills span diverse aspects. The top 10 skills with the highest average required\nhuman agency encompass a broad range, from interpersonal and organizational abilities to\ndecision-making and quality judgment.\n\nThese findings provide early signals of how AI agent integration may reshape core occupational\ncompetencies. As workplace AI agents continue to evolve, longitudinal tracking of task-level changes\ncould yield further insights into how human roles and required skills evolve.\n\n4 Related Work\n\nDigital AI Agents The aspiration to build AI agents capable of dynamically directing their own\nprocesses to accomplish complex goals dates back to the early days of artificial intelligence (Genesereth\nand Nilsson, 1987, McCarthy, 1959). Recent advances in foundational models, particularly large\nlanguage models (LLMs), have sparked a surge in the development of digital AI agents that leverage\nLLMs to plan actions and interface with external tools (Sumers et al., 2023, Wang et al., 2024a). These\nagents have demonstrated the ability to carry out workflows across diverse domains, including\nsoftware engineering (Wang et al., 2024b, Yang et al., 2024), analytical writing (Jiang et al., 2024, Shao\net al., 2024a), and customer support (Yao et al., 2024).\nWhile many of these agents are designed for full automation, they can also be structured to collaborate\nwith humans. Collaborative Gym (Shao et al., 2024b) pioneered the concept of human-agent\ncollaboration, demonstrating that for certain tasks, joint human-agent performance can surpass\nthat of fully autonomous agents, even when those agents are capable of completing the tasks\nindependently. This underscores the potential of AI agents to augment, rather than simply replace,\nhuman labor (Brynjolfsson, 2022). The auditing framework proposed in this work systematically\nexamines augmentation versus automation by introducing the Human Agency Scale (HAS), which\nevaluates the level of ideal human involvement across different workflows.\nOne limitation of prior work on AI agents is its frequent focus on a narrow set of domains. Existing\nbenchmarks, such as GAIA (Mialon et al., 2023), AgentBench (Liu et al., 2023), OSWorld (Xie et al.,\n2024), while valuable for assessing agent capabilities, often rely on task collections that are curated in\na constrained manner. Such approach, while useful for capability evaluation, fails to provide a holistic\nand worker-centric understanding of how these agents could be integrated into the broader workforce.\nBy sourcing tasks from the U.S. Department of Labor’s O*NET database, our work provides a more\ncomprehensive and systematic understanding of the potential landscape for digital AI agents.\nThe Economic Impacts of Generative AI A broad body of work in digital economics has examined\nthe implications of AI, spanning from early machine learning models (Brynjolfsson and Mitchell,\n2017) and computer vision systems (Svanberg et al., 2024) to the recent surge of large language models\n(LLMs) and generative AI (Demirci et al., 2025, Eloundou et al., 2023, Handa et al., 2025, Hoffmann et al.,\n2024). Following the launch of ChatGPT, Eloundou et al. (2023) provided an early analysis of LLMs’\npotential labor market impact, estimating that approximately 80% of the U.S. workforce has at least\nsome tasks exposed to LLM capabilities. However, their analysis did not incorporate the dimension of\n\n15\n\n\n\nworker desire and focused primarily on LLM via ChatGPT or the OpenAI playground rather than the\nbroader scope of AI agents. More recent work leveraging real user data from Claude.ai, a state-of-the-\nart LLM chatbot, to identify which economic tasks users actually perform with AI (Handa et al., 2025).\nIn parallel, field studies in customer support organizations have shown that AI-assisted chatbots can\nimprove worker productivity (Brynjolfsson et al., 2025). As AI agents continue to evolve beyond stan-\ndalone LLM chatbots, our study provides an early audit of their readiness for workplace integration.\n\n5 Conclusion\n\nAdvancements in AI agents are unlocking a wide range of possibilities that may fundamentally\nreshape the workplace. This paper presents the first large-scale audit of both worker desire and\ntechnological capability for AI agents in the context of automation and augmentation. Based on\ndata collected between January and May 2025, we construct the WORKBank database and find that\ndomain workers generally express positive attitudes toward AI agent automation, particularly for\nrepetitive and low-value tasks.\nBy integrating both worker and expert perspectives, we introduce the automation desire–capability\nlandscape, which offers actionable insights for prioritizing AI agent research and investment. Besides\nthe traditional automate-or-not dichotomy, our Human Agency Scale (HAS) uncovers diverse\npatterns of AI integration across occupations, with a dominant inverted-U trend that underscores\nthe potential for human–agent collaboration.\nBeyond informing AI agent research and deployment strategies, our findings also have implications for\nworkforce development. As AI agents reshape the demand for core human skills, our findings suggest\nthat examining strategies for worker reskilling and retraining is a valuable direction for future research.\n\nLimitations While our audit offers a comprehensive snapshot of worker perspectives and\ntechnological capabilities of workplace AI agents, several limitations should be considered:\nFirst, our quantitative assessments are grounded in existing occupational tasks defined by the O*NET\ndatabase, which does not account for new tasks that may emerge as AI agents become more integrated\ninto the workplace. Further analysis of the open-ended worker transcripts could uncover emerging\ntask patterns and enrich our understanding of evolving occupational tasks.\nSecond, although we guided participants to reflect on potential job loss and task enjoyment, domain\nworkers may still lack full awareness of the evolving capabilities and limitations of AI agents (Hazra\net al., 2025), potentially shaping their responses. We partially mitigate this limitation by including\nonly occupations with at least 10 worker responses in the AI Agent WORKBank. Robustness checks\nand further discussion are provided in Appendix B, and complement it with AI experts’ assessment.\nFrom an incentive perspective, some workers may also withhold honest feedback due to concerns\nabout job security or surveillance. We recognize that this is a real concern, which is why we’re\ncommitted to a worker-focused approach that surfaces real concerns and co-designs systems that\nreflect workers’ values. We see such resistance as a critical input that helps guide responsible\ndeployment. By prioritizing workers’ perspectives, we enable workers to play an active role in\nshaping the future of work, rather than just adapting to it.\nThird, the current version of AI Agent WORKBank only covers 104 occupations, a subset of the 287\ncomputer-using occupations identified with the O*NET database. In our study, we launched the\nsurvey interface on Prolific, Upwork, and LinkedIn in January 2025 and concluded data collection\nin May 2025 to ensure temporal consistency. These 104 occupations were retained after filtering\nfor adequate representation (≥10 participants per occupation). While our database exhibits strong\n\n16\n\n\n\ncoverage and demographic representativeness (see Appendix D), our findings may not cover the\nfull picture of AI agents for the workplace.\nFinally, the AI Agent WORKBank reflects the present state of generative AI and agentic systems\nas of early 2025. As AI capabilities continue to evolve, the landscape of feasible and desirable\nagent-supported tasks will likely shift. While our framework offers a timely and structured baseline,\nfuture iterations of this audit will be essential for tracking long-term trends and informing the\nresponsible development of workplace AI systems.\n\nAcknowledgements\n\nWe would like to thank Chuchu Jin and Yanzhe Zhang for their voluntary help in distributing the\nsurvey interface on Linkedin. We are grateful to Hao Zhu for database setup, to Will Held, Dora Zhao,\nOmar Shaikh, Yifan Mai, Sunny Yu, Zachary Robertson for their valuable feedback on the manuscript,\nand to all members of Stanford SALT lab for their suggestions at different stages of this project. This\nwork would not have been possible without the thoughtful participation of the 1,500 domain workers\nand 52 AI experts who contributed to the study. This research is supported in part by grants from\nONR grant N000142412532, and NSF grant IIS-2247357.\n\nReferences\nBen Armstrong, Valerie K. Chen, Alex Cuellar, Alexandra Forsey-Smerek, and Julie A. Shah. Au-\n\ntomation from the worker’s perspective, 2024. URL https://arxiv.org/abs/2409.20387.\n\nDavid H Autor. Why are there still so many jobs? the history and future of workplace automation.\nJournal of economic perspectives, 29(3):3–30, 2015.\n\nDavid H Autor, Frank Levy, and Richard J Murnane. The skill content of recent technological change:\nAn empirical exploration. The Quarterly journal of economics, 118(4):1279–1333, 2003.\n\nErik Brynjolfsson. The turing trap: The promise & peril of human-like artificial intelligence. Daedalus,\n151(2):272–287, 2022.\n\nErik Brynjolfsson and Tom Mitchell. What can machine learning do? workforce implications. Science,\n358(6370):1530–1534, 2017.\n\nErik Brynjolfsson, Danielle Li, and Lindsey Raymond. Generative ai at work. The Quarterly Journal\nof Economics, page qjae044, 2025.\n\nCristiano Castelfranchi. Guarantees for autonomy in cognitive agent architecture. In International\nworkshop on agent theories, architectures, and languages, pages 56–70. Springer, 1994.\n\nSAE On-Road Automated Vehicle Standards Committee et al. Taxonomy and definitions for terms\nrelated to on-road motor vehicle automated driving systems. SAE Standard J, 3016:1, 2014.\n\nOzge Demirci, Jonas Hannane, and Xinrong Zhu. Who is ai replacing? the impact of generative ai\non online freelancing platforms. Management Science, 2025.\n\nMatthew S Dey and Mark A Loewenstein. On job requirements, skill, and wages. US Department of\nLabor, US Bureau of Labor Statistics, Office of Employment . . . , 2019.\n\nAndrea L Eisfeldt, Gregor Schubert, Miao Ben Zhang, and Bledi Taska. The labor impact of generative\nai on firm values. Available at SSRN 4436627, 2023.\n\n17\n\nhttps://arxiv.org/abs/2409.20387\n\n\nTyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. Gpts are gpts: An\nearly look at the labor market impact potential of large language models, 2023. URL\nhttps://arxiv.org/abs/2303.10130.\n\nRosanna Fanni, Valerie Eveline Steinkogler, Giulia Zampedri, and Jo Pierson. Enhancing human\nagency through redress in artificial intelligence systems. AI & society, 38(2):537–547, 2023.\n\nMorgan R Frank, David Autor, James E Bessen, Erik Brynjolfsson, Manuel Cebrian, David J Deming,\nMaryann Feldman, Matthew Groh, José Lobo, Esteban Moro, et al. Toward understanding the\nimpact of artificial intelligence on labor. Proceedings of the National Academy of Sciences, 116(14):\n6531–6539, 2019.\n\nM. R. Genesereth and Nils J. Nilsson. Logical Foundations of Artificial Intelligence. 1987.\n\nAnna F. Gödöllei and James W. Beck. Insecure or optimistic? employees’ diverging appraisals\nof automation, and consequences for job attitudes. Computers in Human Behavior Reports,\n12:100342, 2023. ISSN 2451-9588. doi: https://doi.org/10.1016/j.chbr.2023.100342. URL\nhttps://www.sciencedirect.com/science/article/pii/S2451958823000751.\n\nKunal Handa, Alex Tamkin, Miles McCain, Saffron Huang, Esin Durmus, Sarah Heck, Jared Mueller,\nJerry Hong, Stuart Ritchie, Tim Belonax, et al. Which economic tasks are performed with ai?\nevidence from millions of claude conversations. arXiv preprint arXiv:2503.04761, 2025.\n\nSanchaita Hazra, Bodhisattwa Prasad Majumder, and Tuhin Chakrabarty. Ai safety should prioritize\nthe future of work. arXiv preprint arXiv:2504.13959, 2025.\n\nManuel Hoffmann, Sam Boysel, Frank Nagle, Sida Peng, and Kevin Xu. Generative ai and the nature\nof work. Technical report, CESifo Working Paper, 2024.\n\nYucheng Jiang, Yijia Shao, Dekun Ma, Sina Semnani, and Monica Lam. Into the unknown unknowns:\nEngaged human learning through participation in language model agent conversations. In Pro-\nceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 9917–9955,\nMiami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/\nv1/2024.emnlp-main.554. URL https://aclanthology.org/2024.emnlp-main.554/.\n\nMichelle S Lam, Janice Teoh, James A Landay, Jeffrey Heer, and Michael S Bernstein. Concept\ninduction: Analyzing unstructured text with high-level concepts using lloom. In Proceedings of\nthe 2024 CHI Conference on Human Factors in Computing Systems, pages 1–28, 2024.\n\nXiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen\nMen, Kejuan Yang, et al. Agentbench: Evaluating llms as agents. arXiv preprint arXiv:2308.03688,\n2023.\n\nJohn McCarthy. Programs with common sense, 1959.\n\nGrégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a bench-\nmark for general ai assistants. In The Twelfth International Conference on Learning Representations, 2023.\n\nMargaret Mitchell, Avijit Ghosh, Alexandra Sasha Luccioni, and Giada Pistilli. Fully autonomous\nai agents should not be developed. arXiv preprint arXiv:2502.02649, 2025.\n\nRaja Parasuraman. Designing automation for human use: empirical studies and quantitative models.\nErgonomics, 43(7):931–951, 2000.\n\n18\n\nhttps://arxiv.org/abs/2303.10130\nhttps://www.sciencedirect.com/science/article/pii/S2451958823000751\nhttps://aclanthology.org/2024.emnlp-main.554/\n\n\nS. Russell and P. Norvig. Artificial Intelligence: A Modern Approach. Series in Artificial Intelligence.\nPrentice-Hall, Englewood Cliffs, NJ, 1995.\n\nChirag Shah and Ryen W. White. Agents are not enough. 2024. URL https://arxiv.org/abs/\n2412.16241.\n\nYijia Shao, Yucheng Jiang, Theodore Kanell, Peter Xu, Omar Khattab, and Monica Lam. Assisting\nin writing Wikipedia-like articles from scratch with large language models. In Proceedings of\nthe 2024 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies (Volume 1: Long Papers), pages 6252–6278, Mexico City, Mexico, June\n2024a. Association for Computational Linguistics. doi: 10.18653/v1/2024.naacl-long.347. URL\nhttps://aclanthology.org/2024.naacl-long.347/.\n\nYijia Shao, Vinay Samuel, Yucheng Jiang, John Yang, and Diyi Yang. Collaborative gym: A framework\nfor enabling and evaluating human-agent collaboration. arXiv preprint arXiv:2412.15701, 2024b.\n\nTheodore Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas Griffiths. Cognitive architectures\nfor language agents. Transactions on Machine Learning Research, 2023.\n\nMaja Svanberg, Wensu Li, Martin Fleming, Brian Goehring, and Neil Thompson. Beyond ai exposure:\nWhich tasks are cost-effective to automate with computer vision? Available at SSRN 4700751, 2024.\n\nSuzanne Tsacoumis and Shannon Willison. O* net analyst occupational skill ratings: Procedures.\nAlexandria, VA: Human Resources Research Organization, 2010.\n\nLei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\nTang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\nFrontiers of Computer Science, 18(6):186345, 2024a.\n\nXingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi\nSong, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian,\nYanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao\nPeng, Heng Ji, and Graham Neubig. OpenHands: An Open Platform for AI Software Developers\nas Generalist Agents, 2024b. URL https://arxiv.org/abs/2407.16741.\n\nMichael Wooldridge and Nicholas R Jennings. Intelligent agents: Theory and practice. The knowledge\nengineering review, 10(2):115–152, 1995.\n\nTianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh J Hua,\nZhoujun Cheng, Dongchan Shin, Fangyu Lei, et al. Osworld: Benchmarking multimodal agents\nfor open-ended tasks in real computer environments. Advances in Neural Information Processing\nSystems, 37:52040–52094, 2024.\n\nJohn Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik R Narasimhan,\nand Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering.\nIn The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024.\n\nShunyu Yao, Noah Shinn, Pedram Razavi, and Karthik Narasimhan. τ -bench: A\nbenchmark for tool-agent-user interaction in real-world domains, 2024. URL https:\n//arxiv.org/abs/2406.12045.\n\nWenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng. Wildchat: 1m\nchatgpt interaction logs in the wild. arXiv preprint arXiv:2405.01470, 2024.\n\n19\n\nhttps://arxiv.org/abs/2412.16241\nhttps://arxiv.org/abs/2412.16241\nhttps://aclanthology.org/2024.naacl-long.347/\nhttps://arxiv.org/abs/2407.16741\nhttps://arxiv.org/abs/2406.12045\nhttps://arxiv.org/abs/2406.12045\n\n\nAppendix\n\nTable of Contents\nA Survey Details 21\n\nB Robustness Analysis 22\nB.1 Annotation Agreement of AI Expert Assessments . . . . . . . . . . . . . . . . . . . . . . . . . . 22\nB.2 Mixed-Effects Model Regression on Worker Responses . . . . . . . . . . . . . . . . . . . . . . . 22\n\nC Usage of External Data and Resources 24\nC.1 Occupational Information Network (O*NET) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nC.2 Occupational Employment and Wage Statistics by U.S. Bureau of Labor Statistics . . . . . . . . . 24\nC.3 Claude.ai Usage Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nC.4 Y Combinator (YC) Company and AI Agent Research Paper Data . . . . . . . . . . . . . . . . . 25\n\nD WORKBank Statistics 28\nD.1 Full List of Included Occupations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nD.2 Coverage of the U.S. Workforce . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nD.3 Domain Worker Demographic Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n\nE Additional Results 30\nE.1 Top 20 Tasks Workers Want Automated . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\nE.2 Bottom 20 Tasks Workers Want Automated . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nE.3 Y Combinator Investment Patterns Across Task Zones . . . . . . . . . . . . . . . . . . . . . . . . 32\nE.4 Full Human Agency Scale Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\nE.5 Top 10 Occupations By Worker-Expert Discrepancies in HAS Ratings . . . . . . . . . . . . . . . 34\nE.6 Task to Skill Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n\nF Audio Response Analysis 36\nF.1 LLM-based Topic Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\nF.2 Audio Response Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n\n20\n\n\n\nA Survey Details\n\nWe instantiate our auditing framework (see §2) with an audio-enhanced, semi-structured survey\ninterface to collect first-hand data from domain workers who actually perform those tasks. Our\nsurvey is structured as follows:\n\n• A Mini-interview Section designed to explore participants’ work process and perspectives on\nthe role of AI agents in their work. This section consists of five open-ended questions, allowing\nparticipants to share their thoughts freely and edit their audio transcripts in real time:\nA1 Could you please briefly describe what you do for your work?\nA2 What tasks do you typically do for your work? Think about this question based on the time\n\nyou spend on each of them.\nA3 Please tell us more about the tools or software you use for these tasks. Please try to sort\n\nthem by usage frequency.\nA4 For the three tasks that you spend the most of your time on, could you walk us through\n\nyour process of completing each of them?\nA5 How do you envision using AI in your daily work?\n\n• A Task Rating Section assessing both automation desire (Aw(t)) and the desired Human\nAgency Scale level (Hw(t)) for tasks associated with the participant’s occupation. For each task,\nparticipants respond to a series of structured questions. Items T.I3, T.A1–A3, and T.C1–C5 are\nall rated on a 5-point Likert scale:\n\nTASK FAMILARITY QUESTIONS:\nT.I1 Have you done this task before?\n\n(Yes/No; if “No”, remaining questions are skipped.)\nT.I2a With respect to this task, I consider myself a...\n\n(Novice, Average, Expert)\nT.I2b How much time do you spend on this task in your daily work schedule?\n\n(10%, 30%, 50%, 70%, 100%)\nT.I3 How closely is this task related to your core skills or unique strengths that are essential\n\nto your job?\nAUTOMATION DESIRE RATING QUESTIONS:\n\nT.A1 If an AI can do this task for you completely, how worried would you be that your job will\nbe replaced?\n\nT.A2 Without thinking about salary, how much do you enjoy doing this task?\nT.A3 If an AI can do this task for you completely, how much do you want an AI to do it for you?\nT.A4 Why would you like this task to be automated by AI? (Shown if T.A3 ≥ 3; multi-select\n\noptions):\n\n* Automating this task would free up my time for higher-value work.\n* This task is repetitive or tedious.\n* Automating this task would improve the quality of my work.\n* The task is stressful or mentally draining.\n* This task is complicated or difficult.\n* Automating this task would help me scale and handle higher output.\n\nHUMAN AGENCY SCALE RATING QUESTIONS:\nT.C1 How much does this task require taking physical actions or physical labor?\n\n21\n\n\n\nT.C2 How much does this task require dealing with uncertainty or making high-stake decisions?\nT.C3 How much does this task require specific domain expertise (such as specialized knowledge,\n\nunspoken wisdom, or insights gained through experience)?\nT.C4 How much does this task depend on interpersonal communication or empathy?\nT.C5 If AI were to assist in this task, how much of your collaboration would be needed to\n\ncomplete this task effectively? (References to H1 to H5 are provided)\nT.C6 Why would collaboration be needed for this task? (Shown if T.C5 ≥ 3; multi-select options):\n\n* This task requires physical actions.\n* This task involves making high-stake decisions which I would like to control.\n* This task requires specific domain knowledge.\n* The task involves nuanced communication or interpersonal skills.\n* The task needs validation or oversight to ensure quality.\n* The task is dynamic and requires adapting to changing circumstances.\n* The task has ethical, sensitive, or subjective aspects.\n\n• A Demographic Question Section where we ask about information on age, gender, race, income,\neducation, years of experience in occupation, attitude towards AI, zip code, political orientation,\nand details about their familiarity with LLMs and how they currently use them (i.e., types of\nusage and frequency).\n\nB Robustness Analysis\n\nB.1 Annotation Agreement of AI Expert Assessments\n\nAI experts with practical R&D experience provided ratings for current automation capability\nAe(t) and feasible human-agency levels He(t). To ensure high-quality annotations, we applied the\nfollowing controls:\n\n• Expert qualifications. Each expert satisfied at least one of:\n1. Current PhD student specializing in NLP, large language models, or AI agents.\n2. PhD in Computer Science with demonstrated expertise in AI, LLMs, or agentic systems.\n3. Industry practitioner (e.g., machine learning engineer or research scientist) with hands-on\n\nexperience in LLMs and agentic systems.\nIn total, 52 experts were recruited from institutions including Stanford University, MIT, Google,\nand xAI, etc..\n\n• Assessment protocol. Every task t was independently assessed by at least two experts, with\nadditional reviews to ensure that Ae(t) and He(t) ratings exhibit a standard deviation ≤1.\n\nInter-annotator agreement, measured by Krippendorff’s α, was 0.539 for Ae(t) and 0.511 for He(t).\n\nB.2 Mixed-Effects Model Regression on Worker Responses\n\nTo assess the extent to which workers’ automation desire ratings reflect intrinsic task properties rather\nthan individual demographics, we fitted a linear mixed-effects model of the form\n\nyij=β0+\n\nK∑\nk=1\n\nβkXk,ij+uj+εij ,\n\nuj∼N (0,σ2\nu), εij∼N (0,σ2\n\nε),\n\n22\n\n\n\nVariable Coef. Std.Err. z P>|z| Variable Coef. Std.Err. z P>|z|\n\nIntercept 2.736 0.224 12.208 0.000 llm_usage_by_type__edit[T.Monthly] 0.023 0.065 0.352 0.725\ngender[T.Male] 0.070 0.037 1.909 0.056 llm_usage_by_type__edit[T.Never] -0.185 0.076 -2.447 0.014\ngender[T.Other] -0.210 0.356 -0.591 0.555 llm_usage_by_type__edit[T.Weekly] -0.094 0.047 -2.009 0.045\ngender[T.Prefer not to say] 0.153 0.141 1.084 0.278 llm_usage_by_type__idea_generation[T.Monthly] -0.096 0.062 -1.545 0.122\neducation[T.Bachelor’s Degree] 0.022 0.081 0.268 0.789 llm_usage_by_type__idea_generation[T.Never] 0.072 0.076 0.952 0.341\neducation[T.Doctorate (e.g., PhD)] 0.236 0.113 2.086 0.037 llm_usage_by_type__idea_generation[T.Weekly] -0.014 0.049 -0.279 0.781\neducation[T.High School] 0.037 0.117 0.319 0.750 llm_usage_by_type__communication[T.Monthly] -0.042 0.066 -0.641 0.521\neducation[T.Master’s Degree] 0.121 0.084 1.436 0.151 llm_usage_by_type__communication[T.Never] -0.052 0.067 -0.785 0.432\neducation[T.Prefer not to say] 0.157 0.221 0.711 0.477 llm_usage_by_type__communication[T.Weekly] -0.051 0.047 -1.084 0.278\neducation[T.Professional Degree (e.g., MD, JD)] -0.087 0.130 -0.670 0.503 llm_usage_by_type__analysis[T.Monthly] 0.078 0.067 1.158 0.247\neducation[T.Some College, No Degree] -0.125 0.093 -1.340 0.180 llm_usage_by_type__analysis[T.Never] -0.013 0.080 -0.165 0.869\nexperience[T.3-5 years] 0.100 0.060 1.662 0.097 llm_usage_by_type__analysis[T.Weekly] 0.126 0.052 2.415 0.016\nexperience[T.6-10 years] 0.141 0.065 2.180 0.029 llm_usage_by_type__decision[T.Monthly] 0.022 0.066 0.329 0.742\nexperience[T.Less than 1 year] -0.073 0.120 -0.610 0.542 llm_usage_by_type__decision[T.Never] -0.085 0.077 -1.107 0.268\nexperience[T.More than 10 years] 0.229 0.067 3.415 0.001 llm_usage_by_type__decision[T.Weekly] -0.122 0.054 -2.268 0.023\nllm_familiarity[T.I have some experience using them.] -0.266 0.154 -1.726 0.084 llm_usage_by_type__coding[T.Monthly] -0.021 0.064 -0.328 0.743\nllm_familiarity[T.I use them regularly.] -0.266 0.156 -1.711 0.087 llm_usage_by_type__coding[T.Never] 0.057 0.067 0.850 0.396\nllm_familiarity[T.No, I’ve never heard of them.] 1.370 0.611 2.241 0.025 llm_usage_by_type__coding[T.Weekly] -0.130 0.059 -2.228 0.026\nllm_use_in_work[T.Yes, I use them every day in my work.] 0.077 0.053 1.457 0.145 llm_usage_by_type__system_design[T.Monthly] -0.171 0.073 -2.334 0.020\nllm_use_in_work[T.Yes, I use them every week in my work.] 0.025 0.051 0.493 0.622 llm_usage_by_type__system_design[T.Never] -0.173 0.073 -2.362 0.018\nrace[T.Black] -0.077 0.069 -1.127 0.260 llm_usage_by_type__system_design[T.Weekly] -0.131 0.070 -1.858 0.063\nrace[T.Hispanic] -0.024 0.093 -0.260 0.795 llm_usage_by_type__data_processing[T.Monthly] -0.026 0.060 -0.430 0.667\nrace[T.Native American] -0.209 0.166 -1.257 0.209 llm_usage_by_type__data_processing[T.Never] 0.099 0.061 1.633 0.102\nrace[T.Other] 0.233 0.088 2.657 0.008 llm_usage_by_type__data_processing[T.Weekly] 0.026 0.052 0.494 0.622\nrace[T.White] -0.139 0.062 -2.226 0.026 ai_tedious_work_attitude[T.Somewhat agree] 0.385 0.096 3.991 0.000\nincome[T.165K-209K] 0.209 0.080 2.621 0.009 ai_tedious_work_attitude[T.Somewhat disagree] 0.538 0.128 4.206 0.000\nincome[T.209K-529K] 0.212 0.102 2.076 0.038 ai_tedious_work_attitude[T.Strongly agree] 0.685 0.097 7.098 0.000\nincome[T.30-60K] 0.275 0.063 4.332 0.000 ai_tedious_work_attitude[T.Strongly disagree] 0.439 0.126 3.482 0.000\nincome[T.529K+] 0.687 0.181 3.792 0.000 ai_job_importance_attitude[T.Somewhat agree] -0.027 0.050 -0.534 0.593\nincome[T.60-86K] 0.113 0.066 1.711 0.087 ai_job_importance_attitude[T.Somewhat disagree] -0.040 0.056 -0.720 0.472\nincome[T.86K-165K] 0.089 0.064 1.403 0.161 ai_job_importance_attitude[T.Strongly agree] -0.087 0.065 -1.351 0.177\nincome[T.Prefer not to say] -0.035 0.107 -0.329 0.742 ai_job_importance_attitude[T.Strongly disagree] -0.012 0.071 -0.172 0.864\npolitical_affiliation[T.Green Party] -0.198 1.157 -0.171 0.864 ai_daily_interest_attitude[T.Somewhat agree] 0.128 0.074 1.724 0.085\npolitical_affiliation[T.Independent] -0.074 0.053 -1.403 0.161 ai_daily_interest_attitude[T.Somewhat disagree] 0.027 0.103 0.262 0.793\npolitical_affiliation[T.Libertarian] 0.193 0.125 1.539 0.124 ai_daily_interest_attitude[T.Strongly agree] 0.415 0.078 5.308 0.000\npolitical_affiliation[T.No political affliation] 0.063 0.057 1.092 0.275 ai_daily_interest_attitude[T.Strongly disagree] 0.069 0.109 0.633 0.526\npolitical_affiliation[T.Other] 0.208 0.157 1.328 0.184 ai_suffering_attitude[T.Somewhat agree] -0.299 0.058 -5.191 0.000\npolitical_affiliation[T.Prefer not to answer] 0.136 0.070 1.942 0.052 ai_suffering_attitude[T.Somewhat disagree] -0.047 0.055 -0.852 0.394\npolitical_affiliation[T.Republican] 0.054 0.048 1.140 0.254 ai_suffering_attitude[T.Strongly agree] -0.438 0.074 -5.928 0.000\nllm_usage_by_type__information_access[T.Monthly] -0.082 0.065 -1.256 0.209 ai_suffering_attitude[T.Strongly disagree] -0.023 0.059 -0.391 0.696\nllm_usage_by_type__information_access[T.Never] -0.125 0.077 -1.624 0.104 age -0.003 0.002 -2.033 0.042\nllm_usage_by_type__information_access[T.Weekly] 0.098 0.046 2.149 0.032\n\nTable 1: Fixed-effects estimates from the mixed-effects regression predicting automation desire ratings.\n\nwhere yij is the automation desire rating provided by worker i on task j, Xk,ij are the K demographic\nand attitude covariates (age, gender, education, experience, LLM familiarity/use, income, political\naffiliation, LLM-usage subtypes, and AI-attitude scales), βk their fixed effects, uj a task-specific\nrandom intercept, and εij the residual error. The model was estimated by REML using the\nstatsmodelsMixedLM interface in Python.\nThe fitted model (see Table 1) yielded the following variance-component estimates:\n\nσ̂2\nu=0.066, σ̂2\n\nε =1.254,\n\nimplying an intraclass correlation\n\nICC =\nσ̂2\nu\n\nσ̂2\nu+σ̂2\n\nε\n\n= 0.050,\n\ni.e., roughly 5% of total variance in automation desire is attributable to between-task differences. This\n“small-to-moderate” ICC confirms that task-level properties carry a real signal in workers’ automation\ndesire ratings.\n\nAmong fixed effects, higher educational attainment (“Doctorate” vs. “Bachelor’s”: β̂ = 0.236,\np = 0.037) and greater work experience (“>10 years” vs. “1–2 years”: β̂ = 0.229, p < 0.01) were\nassociated with increased automation desire. Attitudinal scales also showed significant associations:\nStrong agreement that “AI relieves tedious work” predicted higher desire (β̂=0.685, p<0.001), while\n\n23\n\n\n\nstronger “AI suffering” attitudes predicted lower desire (β̂=−0.438, p<0.001). Income levels were\npositively related to automation desire (e.g.“$529K+” vs. “$0–30K”: β̂=0.687, p<0.001).\nTogether, these results indicate that, after controlling for a broad array of individual differences,\ntask identity still explains a meaningful fraction of variance in automation desire. In §3, we use the\naverage ratings for analysis.\n\nC Usage of External Data and Resources\n\nC.1 Occupational Information Network (O*NET)\n\nWe source occupational tasks in this study from O*NET (version 29.2) Task Statements3. The O*NET\ndatabase is a regularly updated database containing information about occupations across the United\nStates. O*NET maps occupations to knowledge, skills, and abilities on different levels of granularity,\nas well as to tasks and detailed work activities. In O*NET, tasks are specific work activities that can be\nunique for each occupation. In total, there are 18,796 task statements spanning across 923 occupations.\nEach task statement is associated with O*NET-SOC Code, Title (i.e., occupation), and Task Type (i.e.,\n“Core”/“Supplementary”). Moreover, O*NET provides annotations of task categories based on the\nfrequency of the task in seven categories (“Yearly or less”, “ More than yearly”, “More than monthly”,\n“More than weekly”, “Daily”, “ Several times daily”, “ Hourly or more”)4. As this work focuses on\ndigital AI agents, we filter these task statements based on the following criteria:\n\n1. The occupation mainly involves using computers in its work as judged by gpt-4o.\n\n2. The task can be finished on the computer as judged by gpt-4o\n\n3. The task does not miss annotation for “Core”/“Supplementary”.\n\n4. The task will be done more than monthly.\n\nAfter filtering, there are 2,131 tasks remaining, spanning across 287 occupations.\n\nPrompt for Filtering Occupations\n\nDoes this job mainly involve using computers?\nAnswer format: “Yes” or “No”\nOccupation: {occupation}\n\nPrompt for Filtering Occupational Tasks\n\nFor {occupation}, is it possible to finish its work-related task on a computer?\nAnswer format: “Yes” or “No”\nTask: {task}\n\nC.2 Occupational Employment and Wage Statistics by U.S. Bureau of Labor Statistics\n\nWe use occupational employment and wage statistics from the U.S. Bureau of Labor Statistics (BLS) to\ncontextualize our findings with economic data. Specifically, we draw on data from the BLS May 2024\n\n3https://www.onetcenter.org/dictionary/29.2/excel/task_statements.html\n4https://www.onetcenter.org/dictionary/29.2/excel/task_categories.html\n\n24\n\n\n\nOccupational Employment and Wage Statistics Query System5 to obtain the “Annual Mean Wage” and\n“Employment” (i.e., number of employees) fields for each occupation in our database. These fields,\ncombined with the collected first-hand data in WORKBank, inform the analysis presented in Figure 7.\n\nC.3 Claude.ai Usage Data\n\nTo shed light on the relationship between current large language model (LLM) usage and future\nworker desires, we compare WORKBank automation desires with existing Claude.ai usage data from\nthe Anthropic Economic Index Handa et al. (2025). The Anthropic dataset reports Claude usage at\nthe task level, following O*NET task definitions. These standardized definitions allow us to directly\nmap tasks from the Anthropic dataset to corresponding tasks in the WORKBank database, enabling\na structured comparison across both sources. Our data shows that the top 10 occupations with the\nhighest average automation desire represent only 1.26% of total usage (Figure 4 c).\n\nC.4 Y Combinator (YC) Company and AI Agent Research Paper Data\n\nWe collect data on Y Combinator (YC) companies and AI agent research papers to assess how\ncurrent investment and research efforts align with the desire–capability landscape revealed by the\nWORKBank database (Figure 5). To enable this analysis, we developed an LLM-assisted pipeline\nthat systematically identifies and maps relevant YC startups and academic publications to specific\noccupational tasks in the WORKBank database.\n\nYC Company Collection Process The full list of YC companies was retrieved on April 28, 2025,\nfrom the official YC website6. The initial dataset comprised 5,156 companies. Company descriptions\nwere collected from their respective YC detail pages and filtered using an LLM-based process\n(gpt-4.1-mini). Each company description was assessed using a binary classification prompt (see\nPrompt for YC Company Classifier) to determine whether the company is AI-relevant. This process\nidentified 1,723 AI-related companies.\n\nAI Agent Research Paper Collection Process Academic papers were obtained from the arXiv\nofficial website7, with a submission cut-off date of April 24, 2025. Papers were first screened by\nkeyword: their title or abstract must contain “language model” (case-insensitive) and either “agent”\nor “system.” This yielded an initial set of 17,064 papers. This set was refined with gpt-4.1-mini\nusing a checklist (see Prompt for AI Agent Paper Classifier) to verify that each paper: (i) describes\ntasks extending beyond single-turn raw text completion, (ii) presents an implemented pipeline, (iii)\nconducts task-level evaluations, and (iv) involves a realistic task scenario. This process produced\na final selection of 1,222 papers. For each paper passing this filter, we performed an additional round\nof task extraction (see Prompt for Paper Task Extractor); the extracted task statement serves as the\npaper’s representative description in the subsequent mapping step.\n\nTask Mapping Process For each YC company and AI agent paper identified through the above\nprocesses, we again employedgpt-4.1-mini to perform binary classification of their applicability to\neach occupational task in the WORKBank database. For YC company-to-task mapping, see Prompt for\nCompany-to-Task Classifier; for agent paper-to-task mapping, see Prompt for Paper-to-Task Classifier.\n\n5https://www.bls.gov/oes/tables.htm\n6https://www.ycombinator.com/companies\n7http://arxiv.org\n\n25\n\nhttps://www.bls.gov/oes/tables.htm\nhttps://www.ycombinator.com/companies\nhttp://arxiv.org\n\n\nPrompt for YC Company Classifier\n\nYou will be presented with a company description. Your job is to classify if the company is an AI related company or\nnot.\nAn AI-related company is defined as a company that is involved in the research, development, or application of AI.\nOutput a boolean value.\n——\nThe description of the company: {company_description}\nThe boolean value indicating if the company is an AI-related company:\n\nPrompt for AI Agent Paper Classifier\n\nYou will see a paper TITLE and ABSTRACT. Return True if the paper’s main contribution is an LLM-driven AGENT\nSYSTEM, else False.\n\nAgent-system criteria (must ALL hold):\n1. Beyond single turn raw text completion - The LLM’s output decides what action or module happens next\n(planner/controller role), beyond single turn raw text completion.\n2. Implemented pipeline - A complete system is actually built and run, not merely proposed.\n3. Task-level evaluation - The paper reports results on the entire system performing its task (automatic metrics or\nuser studies).\n4. Realistic task - The task matches a plausible real-world workflow or a credible simulated environment.\n\nIf ANY criterion is missing, output \"False\".\n——\nThe title of the paper: {paper_title}\nThe abstract of the paper: {paper_abstract}\nWhether the paper is an LLM-driven agent system:\n\nPrompt for Paper Task Extractor\n\nYou will be given the TITLE and ABSTRACT of a research paper describing an agent system. Extract the core task\nthe paper addresses and express it in one concise sentence that begins exactly with: \"The paper proposes an agent\nsystem to solve the task of...\". Your output should be only that sentence, capturing the primary objective of the\nsystem.\n——\nThe title of the paper: {paper_title}\nThe abstract of the paper: {paper_abstract}\nThe core task the paper addresses, expressed in one concise sentence:\n\n26\n\n\n\nPrompt for Company-to-Task Classifier\n\nYou will receive a brief description of a company and its product/service and an indexed list of workflows. For each\nworkflow, decide whether workers involved in that workflow are a primary or explicitly intended user group of the\ncompany’s offering. If the link is merely incidental, indirect, or speculative, mark it False. When in doubt, default to\nFalse.\n——\nThe description of the company: {company_description}\nThe list of workflows and their descriptions: {workflows}\nThe dictionary of occupations and whether they are the target users of the company:\n\nPrompt for Paper-to-Task Classifier\n\nYou will receive a brief description of a task proposed in the paper and an indexed list of workflows. For each\nworkflow, decide whether the task is related to the workflow and the research is applicable to the workflow. If the\nlink is merely incidental, indirect, or speculative, mark it False. When in doubt, default to False.\n——\nThe description of the task proposed in the paper: {task_description}\nThe list of workflows and their descriptions: {workflows}\nThe dictionary of workflows and whether they are related to the task:\n\n27\n\n\n\nD WORKBank Statistics\n\nAs detailed in Section 2.5, we retained only occupations with at least ten worker responses from\nJanuary to May 2025, yielding 1,500 individual assessments across 104 occupations. In this section, we\npresent detailed statistics on occupational coverage and participant demographics in the WORKBank\ndatabase.\n\nD.1 Full List of Included Occupations\n\nOccupation (O*NET-SOC Title) N Occupation (O*NET-SOC Title) N\n\nCustomer Service Representatives 53 Biostatisticians 12\nSales Representatives, Wholesale and Manufacturing, Technical and Scientific Products 35 Quality Control Analysts 12\nAccountants and Auditors 31 Advertising and Promotions Managers 12\nClinical Research Coordinators 30 Budget Analysts 11\nMedical and Health Services Managers 30 Public Relations Specialists 11\nComputer Programmers 28 Financial Managers 11\nWeb Developers 27 Logistics Analysts 11\nComputer and Information Systems Managers 27 Medical Transcriptionists 11\nComputer Systems Analysts 25 Radiologists 11\nPurchasing Managers 24 Eligibility Interviewers, Government Programs 11\nBusiness Teachers, Postsecondary 24 Court, Municipal, and License Clerks 11\nInformation Technology Project Managers 24 Securities, Commodities, and Financial Services Sales Agents 11\nFinancial Quantitative Analysts 23 Sustainability Specialists 11\nInsurance Claims and Policy Processing Clerks 21 Web Administrators 11\nComputer and Information Research Scientists 20 Geographers 11\nLegal Secretaries and Administrative Assistants 19 Management Analysts 11\nSecretaries and Administrative Assistants, Except Legal, Medical, and Executive 18 Bioinformatics Scientists 11\nHuman Resources Specialists 18 News Analysts, Reporters, and Journalists 11\nHuman Resources Managers 17 Compliance Officers 11\nBusiness Intelligence Analysts 17 Video Game Designers 11\nPurchasing Agents, Except Wholesale, Retail, and Farm Products 17 Lawyers 11\nStatisticians 16 Proofreaders and Copy Markers 10\nPersonal Financial Advisors 16 Architects, Except Landscape and Naval 10\nProduction, Planning, and Expediting Clerks 16 Art Directors 10\nComputer User Support Specialists 16 Data Entry Keyers 10\nSearch Marketing Strategists 16 Public Safety Telecommunicators 10\nArchitectural and Civil Drafters 15 Producers and Directors 10\nMedia Technical Directors/Managers 15 Precision Agriculture Technicians 10\nEditors 15 Credit Counselors 10\nTraining and Development Specialists 15 Tax Preparers 10\nTransportation Planners 15 Health Informatics Specialists 10\nAppraisers and Assessors of Real Estate 14 Aerospace Engineers 10\nFundraisers 14 Medical Secretaries and Administrative Assistants 10\nCredit Analysts 14 Technical Writers 10\nWriters and Authors 14 Reservation and Transportation Ticket Agents and Travel Clerks 10\nGraphic Designers 14 Petroleum Engineers 10\nCivil Engineers 14 Molecular and Cellular Biologists 10\nInformation Security Analysts 14 Social Science Research Assistants 10\nOnline Merchants 14 Financial Examiners 10\nMathematicians 13 Telemarketers 10\nTravel Agents 13 Payroll and Timekeeping Clerks 10\nPhotographers 13 Quality Control Systems Managers 10\nSoftware Quality Assurance Analysts and Testers 13 Judicial Law Clerks 10\nBookkeeping, Accounting, and Auditing Clerks 13 Database Administrators 10\nDesktop Publishers 12 Power Distributors and Dispatchers 10\nCost Estimators 12 Energy Engineers, Except Wind and Solar 10\nRegulatory Affairs Managers 12 Network and Computer Systems Administrators 10\nMechanical Engineers 12 Librarians and Media Collections Specialists 10\nSupply Chain Managers 12 Treasurers and Controllers 10\nClinical Data Managers 12 Biofuels Production Managers 10\nComputer Systems Engineers/Architects 12 Mechanical Engineering Technologists and Technicians 10\nLoan Officers 12 Computer Network Support Specialists 10\n\nTable 2: List of occupations covered in the WORKBank database and the number of survey participants\nfrom each occupation.\n\n28\n\n\n\nFigure 8: Demographic distribution of worker participants in our study compared to U.S. workforce\ndemographics for the same set of occupations covered in the WORKBank database, based on data\nfrom the Bureau of Labor Statistics.\n\nD.2 Coverage of the U.S. Workforce\n\nWe evaluate the representativeness of WORKBank by comparing its sector-level distribution with\nU.S. workforce data from the Bureau of Labor Statistics8. Figure 3 presents a breakdown of workforce\ncoverage by sector, contrasting our database with the full U.S. workforce (a) and with the workforce\nrestricted to the 104 occupations included in our database (b). Overall, the comparisons suggest that\nour database captures a broad and representative cross-section of the U.S. workforce at the sector level.\n\nD.3 Domain Worker Demographic Information\n\nWe compare the demographic profile of domain workers in WORKBank with that of the U.S.\nworkforce. U.S. workforce demographic data are sourced from the 2024 Annual Averages of the\nBureau of Labor Statistics (BLS) Current Population Survey9. To ensure a fair comparison, we\nfilter the BLS data to include only the 104 occupations represented in our database. Figure 8 shows\nthe breakdown across key demographic dimensions. Our participant pool has a comprehensive\ndemographic coverage, with a tendency toward younger age groups.\n\n8https://www.bls.gov/oes/tables.htm\n9https://www.bls.gov/cps/tables.htm\n\n29\n\nhttps://www.bls.gov/oes/tables.htm\nhttps://www.bls.gov/cps/tables.htm\n\n\nE Additional Results\n\nE.1 Top 20 Tasks Workers Want Automated\n\nTask\nAverage\n\nAutomation Desire\n\nTax Preparers: Schedule appointments with clients. 5.00\nPublic Safety Telecommunicators: Maintain files of information relating to emergency calls,\nsuch as personnel rosters and emergency call-out and pager files.\n\n4.67\n\nPayroll and Timekeeping Clerks: Issue and record adjustments to pay related to previous\nerrors or retroactive increases.\n\n4.60\n\nDesktop Publishers: Convert various types of files for printing or for the Internet, using\ncomputer software\n\n4.50\n\nOnline Merchants: Create or maintain database of customer accounts. 4.50\nQuality Control Systems Managers: Direct the tracking of defects, test results, or other\nregularly reported quality control data.\n\n4.50\n\nStatisticians: Report results of statistical analyses, including information in the form of\ngraphs, charts, and tables.\n\n4.50\n\nComputer User Support Specialists: Maintain records of daily data communication transactions,\nproblems and remedial actions taken, or installation activities.\n\n4.50\n\nOnline Merchants: Calculate revenue, sales, and expenses, using financial accounting or\nspreadsheet software.\n\n4.40\n\nData Entry Keyers: Store completed documents in appropriate locations. 4.33\nPetroleum Engineers: Maintain records of drilling and production operations. 4.33\nLogistics Analysts: Apply analytic methods or tools to understand, predict, or control logistics\noperations or processes.\n\n4.33\n\nCourt, Municipal, and License Clerks: Instruct parties about timing of court appearances. 4.33\nData Entry Keyers: Maintain logs of activities and completed work. 4.25\nCompliance Officers: Prepare correspondence to inform concerned parties of licensing\ndecisions or appeals processes.\n\n4.25\n\nWeb Developers: Back up files from Web sites to local directories for instant recovery in case\nof problems.\n\n4.20\n\nWeb Administrators: Back up or modify applications and related data to provide for disaster\nrecovery.\n\n4.20\n\nBioinformatics Scientists: Manipulate publicly accessible, commercial, or proprietary genomic,\nproteomic, or post-genomic databases.\n\n4.17\n\nNetwork and Computer Systems Administrators: Perform routine network startup and shutdown\nprocedures, and maintain control records.\n\n4.17\n\nComputer and Information Research Scientists: Approve, prepare, monitor, and adjust\noperational budgets.\n\n4.17\n\nTable 3: Top 20 tasks with highest average automation desire.\n\n30\n\n\n\nE.2 Bottom 20 Tasks Workers Want Automated\n\nTask\nAverage\n\nAutomation Desire\n\nReservation and Transportation Ticket Agents and Travel Clerks: Trace lost, delayed, or\nmisdirected baggage for customers.\n\n1.50\n\nLogistics Analysts: Contact potential vendors to determine material availability. 1.50\nEditors: Write text, such as stories, articles, editorials, or newsletters. 1.60\nReservation and Transportation Ticket Agents and Travel Clerks: Contact customers or\ntravel agents to advise them of travel conveyance changes or to confirm reservations.\n\n1.67\n\nVideo Game Designers: Provide feedback to designers and other colleagues regarding\ngame design features.\n\n1.67\n\nLibrarians and Media Collections Specialists: Code, classify, and catalog books, publications,\nfilms, audio-visual aids, and other library materials, based on subject matter or standard\nlibrary classification systems.\n\n1.67\n\nEditors: Plan the contents of publications according to the publication’s style, editorial\npolicy, and publishing requirements.\n\n1.67\n\nDatabase Administrators: Write and code logical and physical database descriptions and\nspecify identifiers of database to management system, or direct others in coding descriptions.\n\n1.67\n\nGraphic Designers: Key information into computer equipment to create layouts for client or\nsupervisor.\n\n1.67\n\nMechanical Engineering Technologists and Technicians: Calculate required capacities for\nequipment of proposed system to obtain specified performance and submit data to\nengineering personnel for approval.\n\n1.67\n\nSecretaries and Administrative Assistants, Except Legal, Medical, and Executive: Establish\nwork procedures or schedules and keep track of the daily work of clerical staff.\n\n1.67\n\nGraphic Designers: Review final layouts and suggest improvements, as needed. 1.71\nGraphic Designers: Prepare illustrations or rough sketches of material, discussing them with\nclients or supervisors and making necessary changes.\n\n1.71\n\nMechanical Engineering Technologists and Technicians: Interpret engineering sketches,\nspecifications, or drawings.\n\n1.75\n\nAccountants and Auditors: Prepare, examine, or analyze accounting records, financial\nstatements, or other financial reports to assess accuracy, completeness, and conformance to\nreporting and procedural standards.\n\n1.75\n\nEditors: Allocate print space for story text, photos, and illustrations according to space\nparameters and copy significance, using knowledge of layout principles.\n\n1.75\n\nProducers and Directors: Cut and edit film or tape to integrate component parts into desired\nsequences.\n\n1.75\n\nGraphic Designers: Create designs, concepts, and sample layouts, based on knowledge of\nlayout principles and esthetic design concepts.\n\n1.78\n\nLibrarians and Media Collections Specialists: Locate unusual or unique information in response\nto specific requests.\n\n1.80\n\nEditors: Assign topics, events and stories to individual writers or reporters for coverage. 1.80\n\nTable 4: Bottom 20 tasks with lowest average automation desire.\n\n31\n\n\n\nFigure 9: Number of unique newly funded Y Combinator companies mapped to each task zone in\nthe automation desire–capability landscape (2006–2025, through April). Despite the exponential\ngrowth in AI agent startups, the temporal trends across all four zones remain largely parallel. Notably,\nthere is no disproportionate concentration in the Automation “Green Light” or R&D Opportunity\nZones—areas that warrant greater attention.\n\nE.3 Y Combinator Investment Patterns Across Task Zones\n\nAs discussed in §3.2, jointly considering the worker-rated automation desire Aw(t) and expert-\nassessed technological capability Ae(t) divide tasks in WORKBank into four zones: Automation\n“Green Light” Zone, Automation “Red Light” Zone, R&D Opportunity Zone, Low Priority Zone\nFigure 9 illustrates the number of unique newly funded YC companies mapped to each task zone from\n2006 to 2025 (till April). Despite the exponential growth in AI agent startups, the distribution across\nzones has remained relatively uniform over time. Notably, there is no disproportionate concentration\nin the Automation “Green Light” or R&D Opportunity Zones—areas that warrant greater attention.\nWhile the task zone classifications reflect a static snapshot and may not reflect the status in the past, the\nfindings nonetheless suggest a misalignment between where investments are flowing and the joint per-\nspective of both those developing the technology and the workers the technology shall aim to support.\n\n32\n\n\n\nE.4 Full Human Agency Scale Results\n\nWorker-Desired Level\n\nExpert-Rated Feasible Level\n\nD\no\n\nm\nin\n\na\nn\n\nt \nL\n\ne\nv\ne\n\nl \nb\n\ny\n W\n\no\nrk\n\ne\nr-\n\nD\ne\n\ns\nir\n\ne\nd\n\n H\nu\n\nm\na\nn\n\n A\ng\n\ne\nn\n\nc\ny\n\nH\n1\n\nH\n2\n\nH\n3\n\nH\n4\n\nH\n5\n\nFigure 10: Distributions of Human Agency Scale (HAS) levels. The Jensen–Shannon Divergence (JSD)\nquantifies the divergence between the distribution of worker-desired HAS levels (Hw(t)) and expert-assessed\nfeasible HAS levels (He(t)).\n\n\n\nE.5 Top 10 Occupations By Worker-Expert Discrepancies in HAS Ratings\n\nOccupation\nDominant HAS Level\n\nBy Worker Desire\nDominant HAS Level\n\nBy AI Expert Assessment\nJSD\n\nPower Distributors and Dispatchers H4 H3 0.830\nMedical Transcriptionists H2 H1 0.675\nSecurities, Commodities, and Financial Services Sales Agents H2 H1 0.615\nTravel Agents H2 H1 0.571\nFinancial Examiners H4 H1 0.569\nPublic Relations Specialists H3 H4 0.569\nTransportation Planners H3 H4 0.559\nAerospace Engineers H3 H5 0.538\nBookkeeping, Accounting, and Auditing Clerks H2 H1 0.526\nLawyers H3 H2 0.525\n\nTable 5: Top 10 occupations with the largest discrepancies between the worker-desired\nHuman Agency Scale levels Hw(t) and AI expert-assessed feasible levels He(t). The discrep-\nancy is measured by the Jensen–Shannon divergence (JSD) between these two distributions,\nwhere distributions are computed based on all annotated tasks within each occupation.\n\nE.6 Task to Skill Mapping\n\nWe use the O*NET database to map tasks to their related skills (Generalized Work Activities).\nIn order to create broad groups of common skills across multiple tasks, O*NET defines\nthree levels of work activities: Generalized (GWA), Intermediate (IWA), and Detailed Work\nActivities (DWA). Each task in the O*NET database is mapped to one or more DWA’s, which\nthen corresponds to exactly one GWA.\nFor example, the task “Compile financial data to prepare quarterly budget reports” is\nmapped to the DWA “Prepare financial documents, reports, or budgets.” This DWA is\nthen associated with the skill (GWA): “Documenting/Recording Information”. Using this\nmapping, we are able to directly match tasks to their corresponding skills.\nHere, we provide the full descriptions of the skills shown in Figure 7, ordered by decreasing\nrequired human agency (Tsacoumis and Willison, 2010). We exclude physical skills (i.e.,\n“Identifying Objects, Actions, and Events,” “Performing General Physical Activities,”\n“Controlling Machines and Processes,” “Inspecting Equipment, Structures, or Materials,”\n“Handling and Moving Objects,” “Repairing and Maintaining Mechanical Equipment”)\nand “Working with Computers,” as the audit focuses on tasks that are likely to be exposed\nto digital AI agents.\n\n1. Organizing, Planning, and Prioritizing Work: Developing specific goals and plans to\nprioritize, organize, and accomplish your work.\n\n2. Training and Teaching Others: Identifying the educational needs of others, developing\nformal educational or training programs or classes, and teaching or instructing others.\n\n34\n\n\n\n3. Staffing Organizational Units: Recruiting, interviewing, selecting, hiring, and pro-\nmoting employees in an organization.\n\n4. Updating and Using Relevant Knowledge: Keeping up-to-date technically and ap-\nplying new knowledge to your job.\n\n5. Developing Objectives and Strategies: Establishing long-range objectives and speci-\nfying the strategies and actions to achieve them.\n\n6. Guiding, Directing, and Motivating Subordinates: Providing guidance and direction\nto subordinates, including setting performance standards and monitoring perfor-\nmance.\n\n7. Judging the Qualities of Objects, Services, or People: Assessing the value, impor-\ntance, or quality of things or people.\n\n8. Communicating with Supervisors, Peers, or Subordinates: Providing information to\nsupervisors, coworkers, and subordinates by telephone, in written form, e-mail, or in\nperson.\n\n9. Providing Consultation and Advice to Others: Providing guidance and expert advice\nto management or other groups on technical, systems-, or process-related topics.\n\n10. Thinking Creatively: Developing, designing, or creating new applications, ideas,\nrelationships, systems, or products, including artistic contributions.\n\n11. Interpreting the Meaning of Information for Others: Translating or explaining what\ninformation means and how it can be used.\n\n12. Making Decisions and Solving Problems: Analyzing information and evaluating\nresults to choose the best solution and solve problems.\n\n13. Monitoring Processes, Materials, or Surroundings: Monitoring and reviewing infor-\nmation from materials, events, or the environment, to detect or assess problems.\n\n14. Assisting and Caring for Others: Providing personal assistance, medical attention,\nemotional support, or other personal care to others such as coworkers, customers, or\npatients.\n\n15. Getting Information: Observing, receiving, and otherwise obtaining information from\nall relevant sources.\n\n16. Monitoring and Controlling Resources: Monitoring and controlling resources and\noverseeing the spending of money.\n\n17. Analyzing Data or Information: Identifying the underlying principles, reasons, or\nfacts of information by breaking down information or data into separate parts.\n\n18. Selling or Influencing Others: Convincing others to buy merchandise/goods or to\notherwise change their minds or actions.\n\n19. Documenting/Recording Information: Entering, transcribing, recording, storing, of\nmaintaining information in written or electronic/magnetic form.\n\n35\n\n\n\nConcept Percentage of Summaries\n\nLack of trust in accuracy, reliability or capability 45.0%\nFear of job replacement 23.0%\nLack of AI’s human qualities or capabilities 16.3%\nAI not applicable or useful to specific work 15.6%\n\nTable 6: Identified concepts with the seed prompt “The top most common fears that workers\nhave about AI automation in their work”.\n\n20. Evaluating Information to Determine Compliance with Standards: Using relevant\ninformation and individual judgment to determine whether events or processes comply\nwith laws, regulations, or standards.\n\n21. Communicating with People Outside the Organization: Communicating with peo-\nple outside the organization, representing the organization to customers, the public,\ngovernment, and other external sources. The information can be exchanged in person,\nin writing, or by telephone or e-mail.\n\n22. Processing Information: Compiling, coding, categorizing, calculating, tabulating,\nauditing, or verifying information or data.\n\n23. Estimating the Quantifiable Characteristics of Products, Events, or Information:\nEstimating sizes, distances, and quantities; or determining time, costs, resources, or\nmaterials needed to perform a work activity.\n\n24. Performing Administrative Activities: Performing day-to-day administrative tasks\nsuch as maintaining information files and processing paperwork.\n\n25. Performing for or Working Directly with the Public: Performing for people or dealing\ndirectly with the public. This includes serving customers in restaurants and stores, and\nreceiving clients or guests.\n\n26. Scheduling Work and Activities: Scheduling events, programs, and activities, as well\nas the work of others.\n\n27. Establishing and Maintaining Interpersonal Relationships: Developing constructive\nand cooperative working relationships with others, and maintaining them over time.\n\nF Audio Response Analysis\n\nF.1 LLM-based Topic Modeling\n\nTo analyze our audio transcripts collected from workers, we use LLooM (Lam et al., 2024), an\nLLM-based topic modeling tool that takes unstructured text to extract high-level concepts.\nUsing LlooM, we first apply a distillation step with Claude 3 Opus on the audio\ntranscripts. This step filters the text to retain only the most relevant quotes based on a seed\n\n36\n\n\n\nConcept Percentage of Summaries\n\nRole-based support 23.1%\nAssistantship 23.0%\nAutomation 16.5%\nSeparation of Tasks between AI and Humans 12.0%\n\nTable 7: Identified concepts with the seed prompt “If workers want AI to help, what type of\nimagined partnership with AI do they prefer”.\n\nprompt and performs a summarization of the filtered text. Subsequently, we cluster these\nsummarized quotes using the same LLM to form groups of related concepts. We manually\ninspect the clusters to ensure the concepts are distinct and merge any overlapping concepts\nas necessary. Table 6 and Table 7 present the top concept groups identified for two seed\nprompts, corresponding to the analyses in §3.1 and §3.3, respectively.\n\nF.2 Audio Response Examples\n\nF.2.1 Full Transcripts for Direct Quotes in §3.1\n\nArt Director with 6–10 Years of Experience:\n\nSo [my work is] basically just first of all looking through all the tasks in the\n\nsauna at the start of the day. And then once shoots and, you know, filmings are\n\nhappening, looking through the footage and pictures, making sure they adhere to\n\nbrand standards and guidelines and a cohesive voice.\n\n[I spend most of my time] Looking through imagery and making sure that it is\n\nconsistent and always deliverable, and making selects and things of that nature,\n\njust establishing a cohesive tone. [I use] So definitely Bridge, you know, Photo\n\nMechanic, Capture One, Photoshop, Asana for the tasks like I mentioned earlier,\n\nyou know, Gmail, things like that. [For the detailed procedure,] Yeah, looking at\n\nthe imagery as it’s flowing through during the shoot or, you know, filming if it’s\n\nvideo, and then from there going through and selecting and culling and, you know,\n\nagain, only sharing the best imagery that’s cohesive.\n\n[For AI use,] I don’t really, unless it’s, you know, in some sort of minor\n\nway to help the calling process become easier. I don’t want it to be used for\n\ncontent creation. If anything, I want it to be used for seamlessly maximizing\n\nworkflow and, you know, making things less repetitive and tedious and arduous with\n\nworkflow. No content creation.\n\nArt Director with 3-5 Years of Experience:\n\n37\n\n\n\nI manage some anime art projects as part of a company’s public relations and\n\ncommunity strategy for youth engagement. So I work with artists directly, manage\n\nprojects and merchandise and tabling at events and all that fun stuff.\n\nI do a lot of internal meetings just to make sure everyone’s on the same page. It\n\ntakes up a lot of my time. I also have to scope out projects, find artist to work\n\nwith especially those we found on social media, figure out how to get in touch and\n\nwork with them, work with community groups as well, do this type of stuff. And\n\nthen I also help, well not directly do, but help assist in getting merchandise\n\nproduced, including preparing artwork for like production and stuff like that.\n\nI spend a lot of time in Microsoft Word, Microsoft Teams, Outlook, which, you\n\nknow, my company uses Microsoft Office for everything. But then I also use, to\n\ncommunicate with artists, I use the apps that they use. So sometimes that’s LINE,\n\nsometimes that’s Discord, sometimes that’s Twitter. And then I personally have\n\nmy own notion for project management as well.\n\nI spend a lot of time sculpting out projects, so I generally start brainstorming\n\nor collecting all my research, gather all my information into Notion first, and\n\nthen put it into a Word document. The Word document’s a little more formal, but\n\nI also like make sure that’s still approachable to artists, and then I, you know,\n\nexport that as a PDF. For communicating with artists, that depends on what they\n\nuse, but most of them use Discord, so it’s just back and forth. They send us a\n\nsketch, I send that off to my people for, like, feedback very quickly, and then\n\nI, you know, get back to them. I sometimes do have my own autonomy to, like, do\n\nthe final say on what does work and what doesn’t work. And then for at least\n\ngetting everyone on the same page, I spend a lot of time Microsoft Teams. I\n\nobviously have to gather some meeting notes, like, write down some job stuff I\n\nwant to talk about beforehand, make sure there’s no surprises to people, it’s just\n\ncommunicating and providing regular updates.\n\nI would never use AI to like replace artists. I would be more for personal\n\n[project management] use, if anything, it’s to summarize my tasks, for example,\n\nor things like improving my writing, using Apple’s writing tools, where I can\n\njust revise my writing to be a little more concise, but I would never, let it\n\nbrainstorm on my behalf, just because I find AI to be very poorly performing on\n\nthose type of tasks.\n\nGraphic Design with More Than 10 Years of Experience:\n\n38\n\n\n\nI do basically architecture presentation, like graphic design work, work like\n\ntypically. It’s like layout design, which is organizing content, image or text\n\nfor AI storyline, diagram or infographics analysis diagram, render enhancement\n\nlike poster processing, 3D render for a polished look. I also do topography and\n\ncolor scheme using professional fonts and color that align with the project’s\n\ntheme. I also work with board composition, arranging plan, section, elevation\n\nand perspectives. I also work digital and print formatting, which is ensuring\n\nhigh quality output for print or physical brands.\n\nSo, I basically do architectural presentations. Graphic design work typically\n\nincludes layout design, diagram, etc. Later enhancement, like post-printing\n\n3D renders for a polished work. I also give topography color scheme both for\n\nprecision, visibility, and formality. I basically use drawing for autocad and\n\nafter that for render I use Photoshop and Illustrator and for 3D render I use\n\nLumion. So basically I spend a lot of time drafting in AutoCAD. The most common\n\ntasks just likely include creating floor plans, creating sections, creating\n\nelevation, annotation and dimensioning drawings, organizing and managing the\n\nlayers.\n\nAI can be a game-changer in data architect workflow, helping to improve\n\nefficiency, accuracy and even creativity. But I create my design by myself. For\n\nresearch, I use AI.\n\nF.2.2 Transcripts from Occupations Exhibiting High Human Agency (HAS) Levels\n\nAs discussed in §3.3, the Human Agency Scale (HAS) spectrum reveals that very few\noccupations are characterized by a dominant HAS Level 5 (indicating essential human\ninvolvement). “Editors” is the only occupation where workers predominantly desire H5.\nAccording to AI expert assessments, only “Mathematicians” and “Aerospace Engineers”\nfall into this category. Below are representative transcripts for these occupations.\n\nEditor with 3-5 Years of Experience:\n\nI proofread and copy-edit marketing materials, mostly in the travel and tourism\n\nsector. I also do some copywriting and script writing for different ad clients\n\nand some light design work.\n\n39\n\n\n\nI look through flyers, brochures, other marketing materials, and I do several\n\npasses for mistakes in grammar, in consistency, in flow and clarity. And I\n\nmake changes on the document, usually a PDF, and send them back to the client.\n\nThey fix them, they send me another version, and I do several more passes until\n\nwe’ve spent enough time and got it perfect. I mainly use Adobe products, PDFs in\n\nAdobe Reader. I also use Microsoft Word and some Adobe Suite products, mostly\n\nIllustrator and InDesign.\n\nFor copy editing, I read through whatever material the client has sent me. I\n\ndo a pass for basic grammar. I do a pass for clarity and flow, often changing\n\nthe copy significantly to make it sound better. For proofreading, I go through\n\nthe materials. Same thing, but with less of a view toward changing the copy\n\nand more toward finding errors in grammar and consistency and even design. For\n\ncopywriting, I make an outline of my ideas for the project and complete a rough\n\ndraft. Then I spend some time away from it and revise until I have a polished\n\ndraft for the client.\n\nI’m resistant to using AI in my daily workflow. If I’m forced to use it, I would\n\nuse it for basic grammar editing, but I would check each suggestion against my own\n\nknowledge very carefully and give it full consideration before adopting it as a\n\nchange.\n\nEditor With More Than 10 Years of Experience:\n\nSo I work in a media company, [masked], and as an editor I make sure that all\n\nJavaScript that I’m going to print are formatted correctly, the colors are\n\naccurate, and there are no typos.\n\nSo a lot of what I do involves sitting at a computer using productivity tools\n\nlike Adobe Creative Suite, Canva, QuarkXPress, and using the Google Enterprise.\n\nSo for email, document sharing, I use Google Docs quite a bit for my editing\n\npurposes, but I’ll also receive files in PDF format. So just working with all\n\nthe different tools on my computer to get my tasks done every day. So a lot of\n\nwhat I do involves sitting at a computer using productivity tools like Adobe\n\nCreative Suite, Canva, QuarkXPress, and using the Google Enterprise. So for\n\nemail, document sharing, I use Google Docs quite a bit for my editing purposes,\n\nbut I’ll also receive files in PDF format. So just working with all the different\n\ntools on my computer to get my tasks done every day.\n\n40\n\n\n\nSo one of the most frequent pieces of software I use is Adobe Acrobat, and that\n\nis really great for editing PDFs. The next most frequent software I use would be\n\nGoogle Docs. Receiving files through Google Docs, that’s a great way to be able\n\nto provide updates and edits to annotate the files. And then I would say other\n\ntools like Adobe InDesign, Adobe Photoshop, QuarkXPress, Microsoft Publisher.\n\nThose are occasionally used, but that’s really about all four of the frequently\n\nused programs, I would say. So one of the most frequent pieces of software I\n\nuse is Adobe Acrobat, and that is really great for editing PDFs. The next most\n\nfrequent software I use would be Google Docs. Receiving files through Google\n\nDocs, that’s a great way to be able to provide updates and edits to annotate the\n\nfiles. And then I would say other tools like Adobe InDesign, Adobe Photoshop,\n\nQuarkXPress, Microsoft Publisher. Those are occasionally used, but that’s really\n\nabout all four of the frequently used programs, I would say.\n\nSo, when I’m reviewing PDF documents, I will use the markup tool to add comments\n\nand highlight certain sections to make sure that the wording is accurate, or if\n\nthere’s questions regarding the resolution of a photo, I can send that back to\n\nmark that up and say, hey, this needs to be a higher resolution photo, it won’t\n\nprint out correctly. So it’s just a lot of manual review of every single file\n\nbefore it goes to print to make sure that everything is properly formatted, the\n\ncolors are accurate, and it will reproduce correctly, just to make sure everything\n\nlooks good for the customer. So, when I’m reviewing PDF documents, I will use\n\nthe markup tool to add comments and highlight certain sections to make sure that\n\nthe wording is accurate, or if there’s questions regarding the resolution of a\n\nphoto, I can send that back to mark that up and say, hey, this needs to be a higher\n\nresolution photo, it won’t print out correctly. So it’s just a lot of manual\n\nreview of every single file before it goes to print to make sure that everything\n\nis properly formatted, the colors are accurate, and it will reproduce correctly,\n\njust to make sure everything looks good for the customer.\n\nSo, I’m using AI right now when it comes to email, so with the Google suite, there\n\nare Google Gemini tools that help with formatting emails. I can take a very\n\nsimple format for content for email and then using that to expand those topics\n\nand make it more of a wordy email. But I would like to be able to use AI more\n\nin my proofreading and editing than I am right now, so probably within the next\n\ncouple months I should be able to do that.\n\nMathematician With 3-5 Years of Experience:\n\nI do number theory and algebraic geometry, mostly around long-length programs\n\nor categorical long-length programs. [In my daily work, I] read papers and write\n\npapers.\n\n41\n\n\n\nSolving a math problem, I don’t know [whether there is any specific tool to use],\n\njust read papers and have an intuition of what the procedure of philosophy should\n\nbe and work on it.\n\nTo be honest, I think [AI is] useless at this moment.\n\nMathematician With 3-5 Years of Experience:\n\nI am studying geometric representation theory and categorical Langlands program.\n\nMy work involves coming up the problem to work on and learning math tools to help\n\nme think of solutions.\n\nI need to spend a lot of time reading papers and learning math tools. I also\n\nneed to attend the seminar to find collaborators. Then I work on my problem.\n\n[In terms of tools,] I mainly use latex. I spend most of my time studying math.\n\nPapers in my field can have hundreds of pages - it takes a long time to understand\n\nand try to apply the technique.\n\nAt present, I don’t think AI has any use for mathematicians, at least for\n\nDeepSeek and ChatGPT. One core question I am interested in is whether AI can come\n\nup with new stuffs that haven’t been proposed before rather than solving problems\n\npeople craft.\n\nMathematician With 6-10 Years of Experience:\n\nI used to study number theory, in particular, p-adic Hodge theory in arithmetic\n\ngeometry. Now, I work on the formalization of p-adic Hodge theory in Lean and\n\nalso auto-formalization and auto theorem proving.\n\nDuring formalization, I elaborate, generalize, and fill gaps in mathematical\n\nproofs. I design general fomalization frameworks and spend lots of time in Lean\n\ncoding. Lean coding involves searching theorems, formalizing statements and\n\nfilling in formalization details in the proof. The last part is the longest part.\n\nFor auto formalization and formal theorem proving, I spend most of the time coding\n\nto establish the LLM’s training pipeline and preparing data for the training. I\n\nuse the interactive theorem prover Lean. I also use LeanSearch and other tools\n\nrelated to Lean to accelerate. I use Python for LLM training and use DeepSeek for\n\ncoding and debugging.\n\n42\n\n\n\n[Here is a concrete example of my workflow:] I formalized a famous number theory\n\ndefinition, called the period rings of Fontaine. I first wrote down a detailed\n\nversion of the mathematical statements and proofs I need. Splitting the whole\n\nformalization project into several smaller goals. For each smaller goal, I\n\ngeneralize and design suitable definitions and lemmas for formalization. Then\n\nI begin actual formalization using Lean. I first write down the definitions\n\nand state the theorems in Lean without proof. After this, I fill in the proofs\n\nbackwards, searching the library for existing theorems to use and design patterns\n\nto mimic. During formalization, I revise the natural language proof from time to\n\ntime.\n\nI think a primary AI tool could help me in filling in searching for theorems\n\nand design patterns during formalization. A stronger AI tool would do\n\nauto-formalization of theorem statements and provide suggestions in designs.\n\nAn even stronger AI tool would be able to elaborate and fill gaps in mathematical\n\nproofs and autoformalize the human proofs. Additionally, an AI tool strong in\n\ncoding, debugging, and software engineering would help a lot in coding.\n\nAerospace Engineer With 3-5 Years of Experience:\n\nI am an aeronautic engineer. I work in the aircraft maintenance, repairs, design\n\naircraft. I work with [masked].\n\nWe design aircraft, develop, test, and maintain aircrafts, and the systems\n\nthat operate within Earth’s atmosphere, such as airplane, helicopters, drones,\n\nand missiles, though we’re not into missiles, though. Our work focuses on\n\nmaking aircraft, machines, very safe and efficient, capable of flight. We use\n\nComputer-Aided Design as a tool for Autodex, AutoCAD, Cartier, and Solidwork.\n\nAnd we use Computer Fluid Dynamics. It’s ANSYS Fluent, STAR-CNC-MM. What else?\n\nWe use Finite Element Analysis. It’s a tool we use for Nastran.\n\n[In my opinion,] AI is going to be very awesome and it’s going to make it very\n\neasier for us because most of the time, the main problem we have is detecting\n\nwhere the problem is in the engine, you know, so you have to do a lot of manual\n\njobs and all that. So, but if we have AI, you can possibly tell in the dash cam or\n\nwhatever, you know, you can possibly tell.\n\nAerospace Engineer With 1-2 Years of Experience:\n\nI’m a current undergraduate senior and prospective master’s student in aerospace\n\nengineering, working in guidance, navigation, and controls, so like more\n\nsimulation, computer programming side of aerospace engineering.\n\n43\n\n\n\nMost of what I do for work has traditionally been programming simulations to\n\nevaluate vehicle performance for orbital rockets. And so most of my tasks will\n\nbe either building out a part of the simulation, programming new features or new\n\ntesting, or kind of similar types of modeling of different subsystems of the\n\nrocket.\n\nIn general the tools or software that I use would be Visual Studio Code\n\nfor the actual programming. The companies I’ve worked at have used project\n\nmanagement tools like JIRA and Confluence. I think also just a lot of internet\n\ndocumentation is useful. And yeah, I very occasionally would use an AI tool\n\nlike ChatGPT. Generally, my process would be to understand the requirements,\n\nwhich would involve talking to my manager, then kind of going about kind of\n\nlike pre-reading or other types of information gathering necessary for the\n\ntask, actual programming, and then like unit testing and other ways of forms of\n\nvalidation for the programming that I completed.\n\nHonestly, I don’t use AI too much in my current workflow. I think that the only\n\ntime that it could come up would be if I’m running into some type of error or bug\n\nin my program that I can’t find, or kind of a quick piece of code that I could look\n\nup how to do, but it’s easier to just ask a AI model to generate. But honestly, I\n\nuse it very, very infrequently.\n\n44\n\n\n\tIntroduction\n\tAuditing Framework\n\tDefining Audit Granularity and Scope\n\tEmphasizing the Spectrum of Automation and Augmentation\n\tConstructing A Worker-Centric Auditing Framework\n\tEnsuring Dual Perspectives from Both Domain Workers and AI Experts\n\tInstantiating the Audit Framework to Derive WORKBank\n\n\tResults\n\tWorker-centered Views on Occupational Task Automation\n\tDesire-Capability Landscape for AI Agents in the Workplace\n\tHuman Agency Scale (HAS) Spectrum\n\tThe Potential Shift of Core Human Skills\n\n\tRelated Work\n\tConclusion\n\tAppendix\n\t Appendix\n\tSurvey Details\n\tRobustness Analysis\n\tAnnotation Agreement of AI Expert Assessments\n\tMixed-Effects Model Regression on Worker Responses\n\n\tUsage of External Data and Resources\n\tOccupational Information Network (O*NET)\n\tOccupational Employment and Wage Statistics by U.S. Bureau of Labor Statistics\n\tClaude.ai Usage Data\n\tY Combinator (YC) Company and AI Agent Research Paper Data\n\n\tWORKBank Statistics\n\tFull List of Included Occupations\n\tCoverage of the U.S. Workforce\n\tDomain Worker Demographic Information\n\n\tAdditional Results\n\tTop 20 Tasks Workers Want Automated\n\tBottom 20 Tasks Workers Want Automated\n\tY Combinator Investment Patterns Across Task Zones\n\tFull Human Agency Scale Results\n\tTop 10 Occupations By Worker-Expert Discrepancies in HAS Ratings\n\tTask to Skill Mapping\n\n\tAudio Response Analysis\n\tLLM-based Topic Modeling\n\tAudio Response Examples\n\n\n\n",
    "metadata": {
      "arXivID": "https://arxiv.org/abs/2506.06576v2",
      "pdf:PDFVersion": "1.5",
      "xmp:CreatorTool": "arXiv GenPDF (tex2pdf:)",
      "pdf:docinfo:title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce",
      "pdf:hasXFA": "false",
      "X-TIKA:Parsed-By-Full-Set": [
        "org.apache.tika.parser.DefaultParser",
        "org.apache.tika.parser.pdf.PDFParser"
      ],
      "X-TIKA:content_handler": "ToTextContentHandler",
      "License": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "pdf:num3DAnnotations": "0",
      "dc:format": "application/pdf; version=1.5",
      "pdf:docinfo:creator_tool": "arXiv GenPDF (tex2pdf:)",
      "access_permission:fill_in_form": "true",
      "pdf:hasCollection": "false",
      "pdf:encrypted": "false",
      "dc:title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce",
      "pdf:containsNonEmbeddedFont": "true",
      "pdf:hasMarkedContent": "false",
      "pdf:ocrPageCount": "0",
      "DOI": "https://doi.org/10.48550/arXiv.2506.06576",
      "access_permission:can_print_faithful": "true",
      "pdf:docinfo:creator": "Yijia Shao; Humishka Zope; Yucheng Jiang; Jiaxin Pei; David Nguyen; Erik Brynjolfsson; Diyi Yang",
      "PTEX.Fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5",
      "access_permission:extract_for_accessibility": "true",
      "resourceName": "b'2506.06576v2.pdf'",
      "X-TIKA:Parsed-By": [
        "org.apache.tika.parser.DefaultParser",
        "org.apache.tika.parser.pdf.PDFParser"
      ],
      "X-TIKA:embedded_depth": "0",
      "pdf:annotationTypes": [
        "fitz-L0",
        "null"
      ],
      "pdf:docinfo:producer": "pikepdf 8.15.1",
      "pdf:annotationSubtypes": "Link",
      "pdf:containsDamagedFont": "false",
      "pdf:unmappedUnicodeCharsPerPage": [
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "1",
        "5",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0",
        "0"
      ],
      "access_permission:modify_annotations": "true",
      "dc:creator": "Yijia Shao; Humishka Zope; Yucheng Jiang; Jiaxin Pei; David Nguyen; Erik Brynjolfsson; Diyi Yang",
      "pdf:overallPercentageUnmappedUnicodeChars": "5.579630669672042E-5",
      "pdf:docinfo:custom:License": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
      "pdf:docinfo:custom:DOI": "https://doi.org/10.48550/arXiv.2506.06576",
      "pdf:docinfo:custom:PTEX.Fullbanner": "This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5",
      "Content-Length": "7061793",
      "Content-Type": "application/pdf",
      "pdf:producer": "pikepdf 8.15.1",
      "pdf:totalUnmappedUnicodeChars": "6",
      "access_permission:assemble_document": "true",
      "xmpTPg:NPages": "44",
      "pdf:docinfo:custom:arXivID": "https://arxiv.org/abs/2506.06576v2",
      "pdf:hasXMP": "true",
      "pdf:charsPerPage": [
        "2769",
        "3542",
        "3034",
        "2707",
        "2668",
        "2986",
        "2708",
        "2469",
        "3520",
        "2873",
        "3315",
        "2342",
        "3611",
        "3213",
        "3395",
        "3358",
        "2548",
        "2749",
        "2799",
        "1347",
        "2141",
        "2260",
        "5761",
        "2188",
        "2919",
        "1542",
        "967",
        "3404",
        "1205",
        "2077",
        "2560",
        "1255",
        "335",
        "2160",
        "2132",
        "1926",
        "1777",
        "2089",
        "1807",
        "1897",
        "2339",
        "1647",
        "2090",
        "1103"
      ],
      "access_permission:extract_content": "true",
      "access_permission:can_print": "true",
      "pdf:docinfo:trapped": "False",
      "X-TIKA:parse_time_millis": "10598",
      "access_permission:can_modify": "true"
    },
    "output_format": {
      "text": "str",
      "metadata": "dict"
    }
  }
}